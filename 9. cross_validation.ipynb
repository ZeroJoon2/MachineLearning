{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('../data/titanic_train.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 흐름\n",
    "### 1. 데이터 전처리\n",
    "#### 결측치 처리\n",
    "- Age >> 평균  \n",
    "- Cabin : N(모르니깐 N으로 정의)  \n",
    "- Embarked : N(모르니깐 N으로 정의)  \n",
    "\n",
    "#### 컬럼 drop\n",
    "- PassengerID\n",
    "- Name\n",
    "- Ticket\n",
    "\n",
    "#### label encoding - 범주형\n",
    "- Sex\n",
    "- Cabin\n",
    "- Embarked\n",
    "\n",
    "#### 추가 고민사항\n",
    "- Age, Fare(수치형 데이터)\n",
    "    - 그대로 사용할지\n",
    "    - 스케일링\n",
    "    - 비닝\n",
    "\n",
    "\n",
    "### 2. 데이터 분할\n",
    "\n",
    "\n",
    "### 3. 학습\n",
    "#### 교차 검증\n",
    "\n",
    "#### 파라미터 튜닝 + 교차검증\n",
    "- GridSearchCV\n",
    "\n",
    "### 4. feature engineering(정확도 높이기)\n",
    "- 속성 선택(추가 or 삭제 등등)\n",
    "- 파라미터 지정\n",
    "\n",
    "### 5. 하이퍼 파라미터 튜닝\n",
    "- 모델 : RF, LR\n",
    "- 스케일링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.fillna({'Age' : titanic_df['Age'].mean()}, inplace = True)\n",
    "\n",
    "titanic_df.fillna({'Cabin' : 'N'}, inplace=True)\n",
    "\n",
    "titanic_df.fillna({'Embarked' : 'N'}, inplace = True)\n",
    "\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500     N        S\n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2         1       3  female  26.0      0      0   7.9250     N        S\n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4         0       3    male  35.0      0      0   8.0500     N        S"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket'], axis= 1, inplace = True)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500     N        S\n",
       "1         1       1  female  38.0      1      0  71.2833     C        C"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cabin 컬럼은 범주이 너무 많으니 왼쪽 한글자만 사용\n",
    "titanic_df['Cabin'].unique()\n",
    "\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "titanic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500      7         3\n",
       "1         1       1    0  38.0      1      0  71.2833      2         0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Cabin', 'Sex', 'Embarked']\n",
    "\n",
    "for i in col_names:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(titanic_df[i])\n",
    "    titanic_df[i] = le.transform(titanic_df[i])\n",
    "\n",
    "titanic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test \\\n",
    "= train_test_split(X_titanic_df\n",
    "                , y_titanic_df\n",
    "                , test_size=0.2\n",
    "                , random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(random_state=11),\n",
       " RandomForestClassifier(random_state=11),\n",
       " LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lf_clf = LogisticRegression(solver = 'liblinear')\n",
    "dt_clf, rf_clf, lf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사결정트리 : 0.7877094972067039\n",
      "랜덤포레스트 : 0.8547486033519553\n",
      "선형회귀 : 0.8659217877094972\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "lf_clf.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "lf_pred = lf_clf.predict(X_test)\n",
    "\n",
    "print(f'의사결정트리 : {accuracy_score(y_test, dt_pred)}')\n",
    "print(f'랜덤포레스트 : {accuracy_score(y_test, rf_pred)}')\n",
    "print(f'선형회귀 : {accuracy_score(y_test, lf_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(random_state=11),\n",
       " RandomForestClassifier(random_state=11),\n",
       " LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf_cv = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf_cv = RandomForestClassifier(random_state=11)\n",
    "lf_clf_cv = LogisticRegression(solver = 'liblinear')\n",
    "dt_clf_cv, rf_clf_cv, lf_clf_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트 : [0.75419, 0.7809, 0.78652, 0.76966, 0.82022]\n",
      "평균 : 0.782298\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5) #stratified 옵션도 넣어보기\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X_titanic_df):\n",
    "    X_train, X_test = \\\n",
    "    X_titanic_df.values[train_index]\\\n",
    "    , X_titanic_df.values[test_index]\n",
    "\n",
    "    y_train, y_test =\\\n",
    "    y_titanic_df.values[train_index]\\\n",
    "    , y_titanic_df.values[test_index]\n",
    "\n",
    "    dt_clf_cv.fit(X_train, y_train)\n",
    "    pred = dt_clf_cv.predict(X_test)\n",
    "    accuracy = float(np.round(accuracy_score(y_test, pred),5))\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f'리스트 : {scores}')\n",
    "print(f'평균 : {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트 : [0.74302, 0.77528, 0.79213, 0.78652, 0.8427]\n",
      "평균 : 0.78793\n"
     ]
    }
   ],
   "source": [
    "s_kfold = StratifiedKFold(n_splits=5) #stratified 옵션도 넣어보기\n",
    "\n",
    "s_scores = []\n",
    "\n",
    "for train_index, test_index in s_kfold.split(X_titanic_df, y_titanic_df):\n",
    "    X_train, X_test = \\\n",
    "    X_titanic_df.values[train_index]\\\n",
    "    , X_titanic_df.values[test_index]\n",
    "\n",
    "    y_train, y_test =\\\n",
    "    y_titanic_df.values[train_index]\\\n",
    "    , y_titanic_df.values[test_index]\n",
    "\n",
    "    dt_clf_cv.fit(X_train, y_train)\n",
    "    pred = dt_clf_cv.predict(X_test)\n",
    "    accuracy = float(np.round(accuracy_score(y_test, pred),5))\n",
    "    s_scores.append(accuracy)\n",
    "\n",
    "print(f'리스트 : {s_scores}')\n",
    "print(f'평균 : {np.mean(s_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 의사결정트리 모델 성능\n",
      "**************************************************\n",
      "리스트 : [np.float64(0.73333), np.float64(0.78652), np.float64(0.68539), np.float64(0.75281), np.float64(0.82022), np.float64(0.79775), np.float64(0.78652), np.float64(0.75281), np.float64(0.88764), np.float64(0.82022)]\n",
      "평균 : 0.782321\n",
      "\n",
      "▶ 랜덤 포레스트 모델 성능\n",
      "**************************************************\n",
      "리스트 : [np.float64(0.73333), np.float64(0.77528), np.float64(0.76404), np.float64(0.86517), np.float64(0.8427), np.float64(0.8427), np.float64(0.79775), np.float64(0.77528), np.float64(0.91011), np.float64(0.8427)]\n",
      "평균 : 0.814906\n",
      "\n",
      "▶ 선형 모델 성능\n",
      "**************************************************\n",
      "리스트 : [np.float64(0.8), np.float64(0.79775), np.float64(0.76404), np.float64(0.82022), np.float64(0.78652), np.float64(0.76404), np.float64(0.79775), np.float64(0.76404), np.float64(0.83146), np.float64(0.80899)]\n",
      "평균 : 0.793481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 함수로 만들기\n",
    "\n",
    "def best_model(X_df, y_df, n):\n",
    "    dt_scores = []\n",
    "    rf_scores = []\n",
    "    lf_scores = []\n",
    "    dt_clf_cv = DecisionTreeClassifier(random_state=11)\n",
    "    rf_clf_cv = RandomForestClassifier(random_state=11)\n",
    "    lf_clf_cv = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "    s_kfold = StratifiedKFold(n_splits=n)\n",
    "\n",
    "    for train_index, test_index in s_kfold.split(X_df, y_df):\n",
    "\n",
    "        X_train, X_test = X_df.values[train_index], X_df.values[test_index]\n",
    "        y_train, y_test = y_df.values[train_index], y_df.values[test_index]\n",
    "\n",
    "        dt_clf_cv.fit(X_train, y_train)\n",
    "        dt_pred = dt_clf_cv.predict(X_test)\n",
    "        accuracy = np.round(accuracy_score(y_test, dt_pred),5)\n",
    "        dt_scores.append(accuracy)\n",
    "\n",
    "        rf_clf_cv.fit(X_train, y_train)\n",
    "        rf_pred = rf_clf_cv.predict(X_test)\n",
    "        accuracy = np.round(accuracy_score(y_test, rf_pred),5)\n",
    "        rf_scores.append(accuracy)\n",
    "\n",
    "        lf_clf_cv.fit(X_train, y_train)\n",
    "        lf_pred = lf_clf_cv.predict(X_test)\n",
    "        accuracy = np.round(accuracy_score(y_test, lf_pred),5)\n",
    "        lf_scores.append(accuracy)\n",
    "\n",
    "    return print(\n",
    "        f'''\n",
    "▶ 의사결정트리 모델 성능\n",
    "{'*'*50}\n",
    "리스트 : {dt_scores}\n",
    "평균 : {np.mean(dt_scores)}\n",
    "\n",
    "▶ 랜덤 포레스트 모델 성능\n",
    "{'*'*50}\n",
    "리스트 : {rf_scores}\n",
    "평균 : {np.mean(rf_scores)}\n",
    "\n",
    "▶ 선형 모델 성능\n",
    "{'*'*50}\n",
    "리스트 : {lf_scores}\n",
    "평균 : {np.mean(lf_scores)}\n",
    "'''\n",
    "    )\n",
    "\n",
    "best_model(X_titanic_df, y_titanic_df, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df.shape[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(random_state=11),\n",
       " RandomForestClassifier(random_state=11),\n",
       " LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf_gcv = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf_gcv = RandomForestClassifier(random_state=11)\n",
    "lf_clf_gcv = LogisticRegression(solver = 'liblinear')\n",
    "dt_clf_gcv, rf_clf_gcv, lf_clf_gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>4.022423e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>4.001646e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.722046e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.771358</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>7.168434e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.771358</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>4.968534e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.798001</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>4.883128e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.798001</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001199      0.000402         0.000804    4.022423e-04   \n",
       "1       0.001199      0.000399         0.001201    4.001646e-04   \n",
       "2       0.001400      0.000490         0.001000    5.722046e-07   \n",
       "3       0.001199      0.000400         0.001000    7.168434e-07   \n",
       "4       0.001394      0.000483         0.000406    4.968534e-04   \n",
       "5       0.001191      0.000405         0.000598    4.883128e-04   \n",
       "\n",
       "   param_max_depth  param_min_samples_split  \\\n",
       "0                1                        2   \n",
       "1                1                        3   \n",
       "2                2                        2   \n",
       "3                2                        3   \n",
       "4                3                        2   \n",
       "5                3                        3   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}           0.804196   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}           0.804196   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}           0.748252   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}           0.748252   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}           0.797203   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}           0.797203   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.762238           0.825175           0.774648           0.746479   \n",
       "1           0.762238           0.825175           0.774648           0.746479   \n",
       "2           0.762238           0.825175           0.774648           0.746479   \n",
       "3           0.762238           0.825175           0.774648           0.746479   \n",
       "4           0.804196           0.818182           0.795775           0.774648   \n",
       "5           0.804196           0.818182           0.795775           0.774648   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.782547        0.028501                3  \n",
       "1         0.782547        0.028501                3  \n",
       "2         0.771358        0.028786                5  \n",
       "3         0.771358        0.028786                5  \n",
       "4         0.798001        0.014118                1  \n",
       "5         0.798001        0.014118                1  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTree parameter, RandomForest\n",
    "parameters = {\n",
    "            'max_depth' : [1,2,3]\n",
    "            , 'min_samples_split' : [2,3]\n",
    "            }\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf_gcv\n",
    "                    , param_grid=parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , refit = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(grid_dt_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426966292134831"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_clf = grid_dt_clf.best_estimator_\n",
    "best_dt_pred = best_dt_clf.predict(X_test)\n",
    "accuracy_score(y_test, best_dt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV 의 인자들\n",
    "\n",
    "estimator : 보통 알고리즘을 객체로 만들어 넣어준다.\n",
    "\n",
    "param_grid : 튜닝을 위한 대상 파라미터, 사용될 파라미터를 딕셔너리 형태로 넣어준다.\n",
    "\n",
    "scoring : 예측 성능을 측정할 평가 방법을 넣는다. 분류 알고리즘일 때는, 'accuracy', 'f1', 회귀 알고리즘일 때는 'neg_mean_squared_error', 'r2' 등을 넣을 수 있다.\n",
    "\n",
    "cv : 교차 검증에서 몇개로 분할되는지 지정한다.(정수로 넣어주면 K겹 교차검증이 되고, KFold(k) 이런식으로 넣어주어도 무방 // default 값은 cv=3)\n",
    "\n",
    "refit : True로 하면 최적의 하이퍼 파라미터를 찾아서 estimator를 재학습시킨다. (default 값이 True임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8539325842696629"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확성을 높혀보자\n",
    "parameters = {\n",
    "            'max_depth' : [None, 3, 5, 10, 15] # 깊이를 다양하게 설정함\n",
    "            , 'min_samples_split' : [2,3,5,10] # 최소 분할 샘플 수\n",
    "            , 'min_samples_leaf' : [1,2,4,6] # 최소 노드 샘플 수\n",
    "            }\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf_gcv\n",
    "                    , param_grid=parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , refit = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "best_dt_clf = grid_dt_clf.best_estimator_\n",
    "best_dt_pred = best_dt_clf.predict(X_test)\n",
    "accuracy_score(y_test, best_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651685393258427"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확성을 높혀보자\n",
    "parameters = {\n",
    "            'max_depth' : [None, 3, 5, 10, 15, 20] # 깊이를 다양하게 설정함\n",
    "            , 'min_samples_split' : [2,3,5,10] # 최소 분할 샘플 수\n",
    "            , 'min_samples_leaf' : [1,2,4,6,8,10] # 최소 노드 샘플 수\n",
    "            }\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf_gcv\n",
    "                    , param_grid=parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , refit = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "best_dt_clf = grid_dt_clf.best_estimator_\n",
    "best_dt_pred = best_dt_clf.predict(X_test)\n",
    "accuracy_score(y_test, best_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651685393258427"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확성을 높혀보자\n",
    "parameters = {\n",
    "            'max_depth' : [None, 3, 5, 10, 15, 20, 100] # 깊이를 다양하게 설정함\n",
    "            , 'min_samples_split' : [2,3,5,10] # 최소 분할 샘플 수\n",
    "            , 'min_samples_leaf' : [1,2,4,6,8,10,12] # 최소 노드 샘플 수\n",
    "            }\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf_gcv\n",
    "                    , param_grid=parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , refit = True)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "best_dt_clf = grid_dt_clf.best_estimator_\n",
    "best_dt_pred = best_dt_clf.predict(X_test)\n",
    "accuracy_score(y_test, best_dt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion : 분할 성능 측정 기능\n",
    "\n",
    "min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터수로, 과적합을 제어하는데 주로 사용함. 작게 설정할 수록 분할 노드가 많아져 과적합 가능성이 높아짐.\n",
    "\n",
    "max_depth : 트리의 최대 깊이, 깊이가 깊어지면 과적합될 수 있음.\n",
    "\n",
    "max_features : 최적의 분할을 위해 고려할 최대 feature 개수 (default = None : 데이터 세트의 모든 피처를 사용)\n",
    "\n",
    "min_samples_leaf : 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수 (과적합 제어 용도), 작게 설정 필요\n",
    "\n",
    "max_leaf_nodes : 리프노드의 최대 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 의사결정 모델      \n",
      "DecisionTreeClassifier(min_samples_leaf=8, random_state=11)\n",
      "0.8651685393258427\n",
      "      \n",
      "\n",
      "\n",
      "▶ 랜덤포레스트 모델\n",
      "RandomForestClassifier(max_depth=10, max_features='log2', min_samples_split=5,\n",
      "                       n_estimators=200, random_state=11)      \n",
      "0.8764044943820225\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# 정확성을 높혀보자\n",
    "dt_parameters = {\n",
    "            # 'criterion' : ['gini', 'entropy'],\n",
    "            'max_depth' : [None, 3, 5, 10, 15] # 깊이를 다양하게 설정함\n",
    "            , 'max_leaf_nodes' : [None, 2,3,4,5,6]\n",
    "            , 'min_samples_split' : [2,3,5,6] # 최소 분할 샘플 수\n",
    "            , 'min_samples_leaf' : [1,2,4,6,8] # 최소 노드 샘플 수\n",
    "            ,'max_features' : [None,'sqrt','log2',3,4,5]\n",
    "            }\n",
    "\n",
    "rf_parameters = {\n",
    "    'n_estimators': [100, 200],  # 랜덤 포레스트에 추가\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf_gcv\n",
    "                    , param_grid=dt_parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , n_jobs = -1 # CPU의 병렬 처리를 활성화 함\n",
    "                    , refit = True)\n",
    "\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "best_dt_clf = grid_dt_clf.best_estimator_\n",
    "best_dt_pred = best_dt_clf.predict(X_test)\n",
    "print(f'''\n",
    "▶ 의사결정 모델      \n",
    "{grid_dt_clf.best_estimator_}\n",
    "{accuracy_score(y_test, best_dt_pred)}\n",
    "      '''\n",
    ")\n",
    "\n",
    "grid_rf_clf = GridSearchCV(rf_clf_gcv\n",
    "                    , param_grid=rf_parameters\n",
    "                    , scoring='accuracy'\n",
    "                    , cv = 5\n",
    "                    , n_jobs = -1 # CPU의 병렬 처리를 활성화 함\n",
    "                    , refit = True)\n",
    "\n",
    "grid_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_clf = grid_rf_clf.best_estimator_\n",
    "best_rf_pred = best_rf_clf.predict(X_test)\n",
    "print(f'''\n",
    "\n",
    "▶ 랜덤포레스트 모델\n",
    "{grid_rf_clf.best_estimator_}      \n",
    "{accuracy_score(y_test, best_rf_pred)}\n",
    "      '''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
