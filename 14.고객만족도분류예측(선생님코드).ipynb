{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cust_df = pd.read_csv(\"./kaggle_data/santander-customer-satisfaction/train.csv\", encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "산탄데르 은행 고객 만족도조사 결과\n",
    "피처 - 익명화, 컬럼명 익명화, 수치, 0인 데이터가 대다수 - 희소성\n",
    "타겟 - TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100명중 4명이 불만족하는 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불만족 비율은 : 0.04\n"
     ]
    }
   ],
   "source": [
    "cust_df['TARGET'].value_counts() #0 만족, 1 불만족\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET']==1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "\n",
    "print(f'불만족 비율은 : {unsatisfied_cnt/total_cnt:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최소값, Q1, Q2, Q3 가 0인 피처가 많다.\n",
    "최소값 -999999.000000 인 피처 var3 > Nan > 중위값/최빈값 2로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       "           ...  \n",
       " 231           1\n",
       " 188           1\n",
       " 168           1\n",
       " 135           1\n",
       " 87            1\n",
       "Name: var3, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.var3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처 선택 - id 삭제, var3 은 최빈값 2로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "2     2     23                 0.0                      0.0   \n",
       "3     2     37                 0.0                    195.0   \n",
       "4     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                      0.0                      0.0                0.0  ...   \n",
       "1                      0.0                      0.0                0.0  ...   \n",
       "2                      0.0                      0.0                0.0  ...   \n",
       "3                      0.0                      0.0                0.0  ...   \n",
       "4                      0.0                      0.0                0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
    "\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, y 데이터 분할 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 369), (76020,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]\n",
    "X_features.shape, y_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련/테스트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 shape : (60816, 369), 테스트 데이터 shape : (15204, 369)\n",
      "학습 데이터 값의 비율 : 0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "테스트 데이터  값의 비율 : 0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "#X_train.count()\n",
    "print(f'학습 데이터 shape : {X_train.shape}, 테스트 데이터 shape : {X_test.shape}')\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print(f'학습 데이터 값의 비율 : {y_train.value_counts()/train_cnt}')\n",
    "print(f'테스트 데이터  값의 비율 : {y_test.value_counts()/test_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT 예측기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF 예측기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 예측기 p271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터 > 훈련:검증 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.82179\tvalidation_1-auc:0.80068\n",
      "[1]\tvalidation_0-auc:0.83092\tvalidation_1-auc:0.80941\n",
      "[2]\tvalidation_0-auc:0.83207\tvalidation_1-auc:0.80903\n",
      "[3]\tvalidation_0-auc:0.83288\tvalidation_1-auc:0.80889\n",
      "[4]\tvalidation_0-auc:0.83414\tvalidation_1-auc:0.80924\n",
      "[5]\tvalidation_0-auc:0.83524\tvalidation_1-auc:0.80907\n",
      "[6]\tvalidation_0-auc:0.83568\tvalidation_1-auc:0.81005\n",
      "[7]\tvalidation_0-auc:0.83741\tvalidation_1-auc:0.81088\n",
      "[8]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81305\n",
      "[9]\tvalidation_0-auc:0.83949\tvalidation_1-auc:0.81363\n",
      "[10]\tvalidation_0-auc:0.83908\tvalidation_1-auc:0.81277\n",
      "[11]\tvalidation_0-auc:0.83913\tvalidation_1-auc:0.81260\n",
      "[12]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.81325\n",
      "[13]\tvalidation_0-auc:0.84081\tvalidation_1-auc:0.81329\n",
      "[14]\tvalidation_0-auc:0.84196\tvalidation_1-auc:0.81380\n",
      "[15]\tvalidation_0-auc:0.84394\tvalidation_1-auc:0.81540\n",
      "[16]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.81573\n",
      "[17]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.81577\n",
      "[18]\tvalidation_0-auc:0.84468\tvalidation_1-auc:0.81569\n",
      "[19]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81625\n",
      "[20]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.81619\n",
      "[21]\tvalidation_0-auc:0.84685\tvalidation_1-auc:0.81611\n",
      "[22]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.81671\n",
      "[23]\tvalidation_0-auc:0.84793\tvalidation_1-auc:0.81682\n",
      "[24]\tvalidation_0-auc:0.84825\tvalidation_1-auc:0.81675\n",
      "[25]\tvalidation_0-auc:0.84893\tvalidation_1-auc:0.81647\n",
      "[26]\tvalidation_0-auc:0.85104\tvalidation_1-auc:0.81724\n",
      "[27]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.81764\n",
      "[28]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.81873\n",
      "[29]\tvalidation_0-auc:0.85425\tvalidation_1-auc:0.82038\n",
      "[30]\tvalidation_0-auc:0.85624\tvalidation_1-auc:0.82231\n",
      "[31]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.82223\n",
      "[32]\tvalidation_0-auc:0.85785\tvalidation_1-auc:0.82261\n",
      "[33]\tvalidation_0-auc:0.85878\tvalidation_1-auc:0.82289\n",
      "[34]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82389\n",
      "[35]\tvalidation_0-auc:0.86006\tvalidation_1-auc:0.82446\n",
      "[36]\tvalidation_0-auc:0.86079\tvalidation_1-auc:0.82537\n",
      "[37]\tvalidation_0-auc:0.86101\tvalidation_1-auc:0.82546\n",
      "[38]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.82593\n",
      "[39]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.82610\n",
      "[40]\tvalidation_0-auc:0.86284\tvalidation_1-auc:0.82603\n",
      "[41]\tvalidation_0-auc:0.86314\tvalidation_1-auc:0.82624\n",
      "[42]\tvalidation_0-auc:0.86388\tvalidation_1-auc:0.82694\n",
      "[43]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.82741\n",
      "[44]\tvalidation_0-auc:0.86557\tvalidation_1-auc:0.82757\n",
      "[45]\tvalidation_0-auc:0.86643\tvalidation_1-auc:0.82795\n",
      "[46]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.82860\n",
      "[47]\tvalidation_0-auc:0.86788\tvalidation_1-auc:0.82878\n",
      "[48]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82881\n",
      "[49]\tvalidation_0-auc:0.86902\tvalidation_1-auc:0.83000\n",
      "[50]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.83040\n",
      "[51]\tvalidation_0-auc:0.86992\tvalidation_1-auc:0.83036\n",
      "[52]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83061\n",
      "[53]\tvalidation_0-auc:0.87088\tvalidation_1-auc:0.83071\n",
      "[54]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.83092\n",
      "[55]\tvalidation_0-auc:0.87206\tvalidation_1-auc:0.83143\n",
      "[56]\tvalidation_0-auc:0.87277\tvalidation_1-auc:0.83170\n",
      "[57]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.83171\n",
      "[58]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83168\n",
      "[59]\tvalidation_0-auc:0.87428\tvalidation_1-auc:0.83172\n",
      "[60]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83166\n",
      "[61]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83160\n",
      "[62]\tvalidation_0-auc:0.87618\tvalidation_1-auc:0.83164\n",
      "[63]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83174\n",
      "[64]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.83209\n",
      "[65]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83233\n",
      "[66]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.83246\n",
      "[67]\tvalidation_0-auc:0.87932\tvalidation_1-auc:0.83256\n",
      "[68]\tvalidation_0-auc:0.87982\tvalidation_1-auc:0.83264\n",
      "[69]\tvalidation_0-auc:0.88036\tvalidation_1-auc:0.83250\n",
      "[70]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83226\n",
      "[71]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.83208\n",
      "[72]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83234\n",
      "[73]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83247\n",
      "[74]\tvalidation_0-auc:0.88342\tvalidation_1-auc:0.83244\n",
      "[75]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.83246\n",
      "[76]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.83238\n",
      "[77]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.83224\n",
      "[78]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.83234\n",
      "[79]\tvalidation_0-auc:0.88561\tvalidation_1-auc:0.83233\n",
      "[80]\tvalidation_0-auc:0.88637\tvalidation_1-auc:0.83253\n",
      "[81]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83255\n",
      "[82]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83245\n",
      "[83]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83261\n",
      "[84]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.83249\n",
      "[85]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83263\n",
      "[86]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.83251\n",
      "[87]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83237\n",
      "[88]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.83233\n",
      "[89]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.83231\n",
      "[90]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83222\n",
      "[91]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83236\n",
      "[92]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83218\n",
      "[93]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83239\n",
      "[94]\tvalidation_0-auc:0.89213\tvalidation_1-auc:0.83220\n",
      "[95]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83227\n",
      "[96]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83213\n",
      "[97]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.83223\n",
      "[98]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83209\n",
      "[99]\tvalidation_0-auc:0.89361\tvalidation_1-auc:0.83227\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 7.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8397812474965844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimator=500, learning_rate=0.05, random_state=156)\n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "xgb_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost 하이퍼 파리미터 최적화\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 공간\n",
    "search_space = {\n",
    "    'n_estimator' : scope.int(hp.quniform('n_estimator', 50, 300, 10))\n",
    "    , 'max_depth' : scope.int(hp.quniform('max_depth', 5, 20, 1))\n",
    "    , 'learning_rate' : hp.uniform('learning_rate', 0.01, 0.3) # 지수로 뽑음\n",
    "    , 'subsample' : hp.uniform('subsample', 0.5, 1.0)\n",
    "    , 'colsample_bytree' :hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func_xgb(params):\n",
    "    model = XGBClassifier(\n",
    "        n_estimator = 100 #params['n_estimator']\n",
    "        , max_depth = params['max_depth']\n",
    "        , learning_rate = params['learning_rate']\n",
    "        #, subsample = params['subsample']\n",
    "        , colsample_bytree = params['colsample_bytree']\n",
    "        , random_state = 42\n",
    "        , eval_metric = 'logloss'\n",
    "    )\n",
    "\n",
    "    ### k-Fold 방식 추가해보기\n",
    "\n",
    "    score_mean = cross_val_score(model\n",
    "                                , X_train\n",
    "                                , y_train\n",
    "                                , cv = 5\n",
    "                                , scoring = 'accuracy'\n",
    "                                ).mean()\n",
    "    \n",
    "    return {'loss' : -1 * score_mean, 'status' : STATUS_OK}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:55:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:59:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:59:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:  \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:59:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:59:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:00:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:00:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:00:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:00:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:00:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:01:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:01:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:01:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:01:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:02:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:02:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:02:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:02:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:03:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:05:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:06:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:07:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:07:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:07:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:07:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:07:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:09:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:13:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:15:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:16:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:17:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:18:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:18:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:18:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:18:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:19:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:20:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:21:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:22:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:23:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:24:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:24:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:24:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:24:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:25:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:25:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:25:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:25:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:25:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:26:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:26:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:26:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:26:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:26:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:27:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:28:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:29:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576:   \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "100%|██████████| 50/50 [39:43<00:00, 47.67s/trial, best loss: -0.9610135474017121]\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "best_01 = fmin(fn=objective_func_xgb\n",
    "               , space = search_space\n",
    "               , algo = tpe.suggest\n",
    "               , max_evals = 50\n",
    "               , trials = trial_val\n",
    "               , rstate = np.random.default_rng(seed = 0)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6406824979336891,\n",
       " 'learning_rate': 0.12212214378271394,\n",
       " 'max_depth': 5.0,\n",
       " 'n_estimator': 230.0,\n",
       " 'subsample': 0.6796628299126117}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"closample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.81594\tvalidation_1-auc:0.79980\n",
      "[1]\tvalidation_0-auc:0.82239\tvalidation_1-auc:0.80414\n",
      "[2]\tvalidation_0-auc:0.82849\tvalidation_1-auc:0.80826\n",
      "[3]\tvalidation_0-auc:0.83320\tvalidation_1-auc:0.80867\n",
      "[4]\tvalidation_0-auc:0.83580\tvalidation_1-auc:0.81107\n",
      "[5]\tvalidation_0-auc:0.83559\tvalidation_1-auc:0.81076\n",
      "[6]\tvalidation_0-auc:0.83783\tvalidation_1-auc:0.81346\n",
      "[7]\tvalidation_0-auc:0.83971\tvalidation_1-auc:0.81422\n",
      "[8]\tvalidation_0-auc:0.84113\tvalidation_1-auc:0.81373\n",
      "[9]\tvalidation_0-auc:0.84467\tvalidation_1-auc:0.81816\n",
      "[10]\tvalidation_0-auc:0.84570\tvalidation_1-auc:0.81923\n",
      "[11]\tvalidation_0-auc:0.84688\tvalidation_1-auc:0.82023\n",
      "[12]\tvalidation_0-auc:0.84813\tvalidation_1-auc:0.82031\n",
      "[13]\tvalidation_0-auc:0.85056\tvalidation_1-auc:0.82161\n",
      "[14]\tvalidation_0-auc:0.85147\tvalidation_1-auc:0.82333\n",
      "[15]\tvalidation_0-auc:0.85182\tvalidation_1-auc:0.82321\n",
      "[16]\tvalidation_0-auc:0.85377\tvalidation_1-auc:0.82401\n",
      "[17]\tvalidation_0-auc:0.85526\tvalidation_1-auc:0.82596\n",
      "[18]\tvalidation_0-auc:0.85548\tvalidation_1-auc:0.82610\n",
      "[19]\tvalidation_0-auc:0.85606\tvalidation_1-auc:0.82586\n",
      "[20]\tvalidation_0-auc:0.85714\tvalidation_1-auc:0.82707\n",
      "[21]\tvalidation_0-auc:0.85813\tvalidation_1-auc:0.82730\n",
      "[22]\tvalidation_0-auc:0.86059\tvalidation_1-auc:0.82875\n",
      "[23]\tvalidation_0-auc:0.86129\tvalidation_1-auc:0.82934\n",
      "[24]\tvalidation_0-auc:0.86269\tvalidation_1-auc:0.83048\n",
      "[25]\tvalidation_0-auc:0.86378\tvalidation_1-auc:0.83042\n",
      "[26]\tvalidation_0-auc:0.86431\tvalidation_1-auc:0.83100\n",
      "[27]\tvalidation_0-auc:0.86518\tvalidation_1-auc:0.83134\n",
      "[28]\tvalidation_0-auc:0.86609\tvalidation_1-auc:0.83160\n",
      "[29]\tvalidation_0-auc:0.86696\tvalidation_1-auc:0.83212\n",
      "[30]\tvalidation_0-auc:0.86768\tvalidation_1-auc:0.83244\n",
      "[31]\tvalidation_0-auc:0.86875\tvalidation_1-auc:0.83215\n",
      "[32]\tvalidation_0-auc:0.86966\tvalidation_1-auc:0.83194\n",
      "[33]\tvalidation_0-auc:0.87052\tvalidation_1-auc:0.83202\n",
      "[34]\tvalidation_0-auc:0.87117\tvalidation_1-auc:0.83151\n",
      "[35]\tvalidation_0-auc:0.87204\tvalidation_1-auc:0.83117\n",
      "[36]\tvalidation_0-auc:0.87237\tvalidation_1-auc:0.83061\n",
      "[37]\tvalidation_0-auc:0.87275\tvalidation_1-auc:0.83063\n",
      "[38]\tvalidation_0-auc:0.87348\tvalidation_1-auc:0.83107\n",
      "[39]\tvalidation_0-auc:0.87401\tvalidation_1-auc:0.83084\n",
      "[40]\tvalidation_0-auc:0.87474\tvalidation_1-auc:0.83105\n",
      "[41]\tvalidation_0-auc:0.87610\tvalidation_1-auc:0.83055\n",
      "[42]\tvalidation_0-auc:0.87683\tvalidation_1-auc:0.83067\n",
      "[43]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.83124\n",
      "[44]\tvalidation_0-auc:0.87850\tvalidation_1-auc:0.83115\n",
      "[45]\tvalidation_0-auc:0.87888\tvalidation_1-auc:0.83136\n",
      "[46]\tvalidation_0-auc:0.87949\tvalidation_1-auc:0.83178\n",
      "[47]\tvalidation_0-auc:0.88043\tvalidation_1-auc:0.83220\n",
      "[48]\tvalidation_0-auc:0.88056\tvalidation_1-auc:0.83237\n",
      "[49]\tvalidation_0-auc:0.88124\tvalidation_1-auc:0.83250\n",
      "[50]\tvalidation_0-auc:0.88218\tvalidation_1-auc:0.83248\n",
      "[51]\tvalidation_0-auc:0.88280\tvalidation_1-auc:0.83289\n",
      "[52]\tvalidation_0-auc:0.88332\tvalidation_1-auc:0.83275\n",
      "[53]\tvalidation_0-auc:0.88379\tvalidation_1-auc:0.83319\n",
      "[54]\tvalidation_0-auc:0.88418\tvalidation_1-auc:0.83343\n",
      "[55]\tvalidation_0-auc:0.88465\tvalidation_1-auc:0.83350\n",
      "[56]\tvalidation_0-auc:0.88515\tvalidation_1-auc:0.83361\n",
      "[57]\tvalidation_0-auc:0.88523\tvalidation_1-auc:0.83358\n",
      "[58]\tvalidation_0-auc:0.88593\tvalidation_1-auc:0.83339\n",
      "[59]\tvalidation_0-auc:0.88638\tvalidation_1-auc:0.83324\n",
      "[60]\tvalidation_0-auc:0.88704\tvalidation_1-auc:0.83341\n",
      "[61]\tvalidation_0-auc:0.88755\tvalidation_1-auc:0.83333\n",
      "[62]\tvalidation_0-auc:0.88873\tvalidation_1-auc:0.83299\n",
      "[63]\tvalidation_0-auc:0.88953\tvalidation_1-auc:0.83306\n",
      "[64]\tvalidation_0-auc:0.88966\tvalidation_1-auc:0.83306\n",
      "[65]\tvalidation_0-auc:0.88984\tvalidation_1-auc:0.83310\n",
      "[66]\tvalidation_0-auc:0.89016\tvalidation_1-auc:0.83333\n",
      "[67]\tvalidation_0-auc:0.89026\tvalidation_1-auc:0.83339\n",
      "[68]\tvalidation_0-auc:0.89074\tvalidation_1-auc:0.83339\n",
      "[69]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83316\n",
      "[70]\tvalidation_0-auc:0.89177\tvalidation_1-auc:0.83317\n",
      "[71]\tvalidation_0-auc:0.89197\tvalidation_1-auc:0.83321\n",
      "[72]\tvalidation_0-auc:0.89255\tvalidation_1-auc:0.83328\n",
      "[73]\tvalidation_0-auc:0.89318\tvalidation_1-auc:0.83296\n",
      "[74]\tvalidation_0-auc:0.89369\tvalidation_1-auc:0.83279\n",
      "[75]\tvalidation_0-auc:0.89407\tvalidation_1-auc:0.83272\n",
      "[76]\tvalidation_0-auc:0.89420\tvalidation_1-auc:0.83265\n",
      "[77]\tvalidation_0-auc:0.89450\tvalidation_1-auc:0.83276\n",
      "[78]\tvalidation_0-auc:0.89505\tvalidation_1-auc:0.83295\n",
      "[79]\tvalidation_0-auc:0.89574\tvalidation_1-auc:0.83280\n",
      "[80]\tvalidation_0-auc:0.89594\tvalidation_1-auc:0.83285\n",
      "[81]\tvalidation_0-auc:0.89620\tvalidation_1-auc:0.83290\n",
      "[82]\tvalidation_0-auc:0.89634\tvalidation_1-auc:0.83312\n",
      "[83]\tvalidation_0-auc:0.89656\tvalidation_1-auc:0.83306\n",
      "[84]\tvalidation_0-auc:0.89716\tvalidation_1-auc:0.83339\n",
      "[85]\tvalidation_0-auc:0.89736\tvalidation_1-auc:0.83324\n",
      "[86]\tvalidation_0-auc:0.89796\tvalidation_1-auc:0.83317\n",
      "[87]\tvalidation_0-auc:0.89859\tvalidation_1-auc:0.83331\n",
      "[88]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.83339\n",
      "[89]\tvalidation_0-auc:0.89943\tvalidation_1-auc:0.83341\n",
      "[90]\tvalidation_0-auc:0.89987\tvalidation_1-auc:0.83343\n",
      "[91]\tvalidation_0-auc:0.90033\tvalidation_1-auc:0.83364\n",
      "[92]\tvalidation_0-auc:0.90043\tvalidation_1-auc:0.83379\n",
      "[93]\tvalidation_0-auc:0.90075\tvalidation_1-auc:0.83346\n",
      "[94]\tvalidation_0-auc:0.90120\tvalidation_1-auc:0.83385\n",
      "[95]\tvalidation_0-auc:0.90178\tvalidation_1-auc:0.83380\n",
      "[96]\tvalidation_0-auc:0.90233\tvalidation_1-auc:0.83360\n",
      "[97]\tvalidation_0-auc:0.90248\tvalidation_1-auc:0.83375\n",
      "[98]\tvalidation_0-auc:0.90294\tvalidation_1-auc:0.83371\n",
      "[99]\tvalidation_0-auc:0.90334\tvalidation_1-auc:0.83371\n",
      "[100]\tvalidation_0-auc:0.90368\tvalidation_1-auc:0.83408\n",
      "[101]\tvalidation_0-auc:0.90403\tvalidation_1-auc:0.83383\n",
      "[102]\tvalidation_0-auc:0.90466\tvalidation_1-auc:0.83354\n",
      "[103]\tvalidation_0-auc:0.90480\tvalidation_1-auc:0.83347\n",
      "[104]\tvalidation_0-auc:0.90524\tvalidation_1-auc:0.83383\n",
      "[105]\tvalidation_0-auc:0.90544\tvalidation_1-auc:0.83382\n",
      "[106]\tvalidation_0-auc:0.90577\tvalidation_1-auc:0.83333\n",
      "[107]\tvalidation_0-auc:0.90611\tvalidation_1-auc:0.83325\n",
      "[108]\tvalidation_0-auc:0.90641\tvalidation_1-auc:0.83335\n",
      "[109]\tvalidation_0-auc:0.90723\tvalidation_1-auc:0.83320\n",
      "[110]\tvalidation_0-auc:0.90762\tvalidation_1-auc:0.83300\n",
      "[111]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.83319\n",
      "[112]\tvalidation_0-auc:0.90841\tvalidation_1-auc:0.83317\n",
      "[113]\tvalidation_0-auc:0.90899\tvalidation_1-auc:0.83320\n",
      "[114]\tvalidation_0-auc:0.90933\tvalidation_1-auc:0.83292\n",
      "[115]\tvalidation_0-auc:0.90976\tvalidation_1-auc:0.83292\n",
      "[116]\tvalidation_0-auc:0.90988\tvalidation_1-auc:0.83286\n",
      "[117]\tvalidation_0-auc:0.91023\tvalidation_1-auc:0.83275\n",
      "[118]\tvalidation_0-auc:0.91070\tvalidation_1-auc:0.83275\n",
      "[119]\tvalidation_0-auc:0.91082\tvalidation_1-auc:0.83283\n",
      "[120]\tvalidation_0-auc:0.91121\tvalidation_1-auc:0.83249\n",
      "[121]\tvalidation_0-auc:0.91148\tvalidation_1-auc:0.83228\n",
      "[122]\tvalidation_0-auc:0.91178\tvalidation_1-auc:0.83234\n",
      "[123]\tvalidation_0-auc:0.91209\tvalidation_1-auc:0.83231\n",
      "[124]\tvalidation_0-auc:0.91234\tvalidation_1-auc:0.83220\n",
      "[125]\tvalidation_0-auc:0.91289\tvalidation_1-auc:0.83186\n",
      "[126]\tvalidation_0-auc:0.91313\tvalidation_1-auc:0.83181\n",
      "[127]\tvalidation_0-auc:0.91349\tvalidation_1-auc:0.83185\n",
      "[128]\tvalidation_0-auc:0.91362\tvalidation_1-auc:0.83187\n",
      "[129]\tvalidation_0-auc:0.91438\tvalidation_1-auc:0.83135\n",
      "[130]\tvalidation_0-auc:0.91465\tvalidation_1-auc:0.83122\n",
      "[131]\tvalidation_0-auc:0.91479\tvalidation_1-auc:0.83109\n",
      "[132]\tvalidation_0-auc:0.91495\tvalidation_1-auc:0.83112\n",
      "[133]\tvalidation_0-auc:0.91505\tvalidation_1-auc:0.83111\n",
      "[134]\tvalidation_0-auc:0.91538\tvalidation_1-auc:0.83106\n",
      "[135]\tvalidation_0-auc:0.91591\tvalidation_1-auc:0.83101\n",
      "[136]\tvalidation_0-auc:0.91639\tvalidation_1-auc:0.83099\n",
      "[137]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.83115\n",
      "[138]\tvalidation_0-auc:0.91688\tvalidation_1-auc:0.83134\n",
      "[139]\tvalidation_0-auc:0.91731\tvalidation_1-auc:0.83128\n",
      "[140]\tvalidation_0-auc:0.91747\tvalidation_1-auc:0.83113\n",
      "[141]\tvalidation_0-auc:0.91771\tvalidation_1-auc:0.83133\n",
      "[142]\tvalidation_0-auc:0.91784\tvalidation_1-auc:0.83139\n",
      "[143]\tvalidation_0-auc:0.91784\tvalidation_1-auc:0.83146\n",
      "[144]\tvalidation_0-auc:0.91822\tvalidation_1-auc:0.83152\n",
      "[145]\tvalidation_0-auc:0.91828\tvalidation_1-auc:0.83159\n",
      "[146]\tvalidation_0-auc:0.91851\tvalidation_1-auc:0.83129\n",
      "[147]\tvalidation_0-auc:0.91884\tvalidation_1-auc:0.83126\n",
      "[148]\tvalidation_0-auc:0.91922\tvalidation_1-auc:0.83091\n",
      "[149]\tvalidation_0-auc:0.91953\tvalidation_1-auc:0.83071\n",
      "[150]\tvalidation_0-auc:0.91983\tvalidation_1-auc:0.83079\n",
      "[151]\tvalidation_0-auc:0.91986\tvalidation_1-auc:0.83068\n",
      "[152]\tvalidation_0-auc:0.92017\tvalidation_1-auc:0.83050\n",
      "[153]\tvalidation_0-auc:0.92033\tvalidation_1-auc:0.83039\n",
      "[154]\tvalidation_0-auc:0.92065\tvalidation_1-auc:0.83014\n",
      "[155]\tvalidation_0-auc:0.92091\tvalidation_1-auc:0.82988\n",
      "[156]\tvalidation_0-auc:0.92102\tvalidation_1-auc:0.82985\n",
      "[157]\tvalidation_0-auc:0.92114\tvalidation_1-auc:0.82988\n",
      "[158]\tvalidation_0-auc:0.92144\tvalidation_1-auc:0.83008\n",
      "[159]\tvalidation_0-auc:0.92182\tvalidation_1-auc:0.83008\n",
      "[160]\tvalidation_0-auc:0.92227\tvalidation_1-auc:0.83030\n",
      "[161]\tvalidation_0-auc:0.92259\tvalidation_1-auc:0.83011\n",
      "[162]\tvalidation_0-auc:0.92279\tvalidation_1-auc:0.83008\n",
      "[163]\tvalidation_0-auc:0.92300\tvalidation_1-auc:0.83007\n",
      "[164]\tvalidation_0-auc:0.92314\tvalidation_1-auc:0.82995\n",
      "[165]\tvalidation_0-auc:0.92344\tvalidation_1-auc:0.82968\n",
      "[166]\tvalidation_0-auc:0.92384\tvalidation_1-auc:0.82944\n",
      "[167]\tvalidation_0-auc:0.92425\tvalidation_1-auc:0.82934\n",
      "[168]\tvalidation_0-auc:0.92486\tvalidation_1-auc:0.82954\n",
      "[169]\tvalidation_0-auc:0.92500\tvalidation_1-auc:0.82943\n",
      "[170]\tvalidation_0-auc:0.92539\tvalidation_1-auc:0.82952\n",
      "[171]\tvalidation_0-auc:0.92549\tvalidation_1-auc:0.82964\n",
      "[172]\tvalidation_0-auc:0.92580\tvalidation_1-auc:0.82939\n",
      "[173]\tvalidation_0-auc:0.92584\tvalidation_1-auc:0.82950\n",
      "[174]\tvalidation_0-auc:0.92598\tvalidation_1-auc:0.82930\n",
      "[175]\tvalidation_0-auc:0.92645\tvalidation_1-auc:0.82900\n",
      "[176]\tvalidation_0-auc:0.92669\tvalidation_1-auc:0.82890\n",
      "[177]\tvalidation_0-auc:0.92692\tvalidation_1-auc:0.82896\n",
      "[178]\tvalidation_0-auc:0.92725\tvalidation_1-auc:0.82866\n",
      "[179]\tvalidation_0-auc:0.92748\tvalidation_1-auc:0.82847\n",
      "[180]\tvalidation_0-auc:0.92782\tvalidation_1-auc:0.82840\n",
      "[181]\tvalidation_0-auc:0.92795\tvalidation_1-auc:0.82834\n",
      "[182]\tvalidation_0-auc:0.92797\tvalidation_1-auc:0.82850\n",
      "[183]\tvalidation_0-auc:0.92814\tvalidation_1-auc:0.82828\n",
      "[184]\tvalidation_0-auc:0.92835\tvalidation_1-auc:0.82818\n",
      "[185]\tvalidation_0-auc:0.92843\tvalidation_1-auc:0.82826\n",
      "[186]\tvalidation_0-auc:0.92849\tvalidation_1-auc:0.82813\n",
      "[187]\tvalidation_0-auc:0.92871\tvalidation_1-auc:0.82803\n",
      "[188]\tvalidation_0-auc:0.92887\tvalidation_1-auc:0.82768\n",
      "[189]\tvalidation_0-auc:0.92927\tvalidation_1-auc:0.82785\n",
      "[190]\tvalidation_0-auc:0.92958\tvalidation_1-auc:0.82811\n",
      "[191]\tvalidation_0-auc:0.92970\tvalidation_1-auc:0.82815\n",
      "[192]\tvalidation_0-auc:0.92978\tvalidation_1-auc:0.82804\n",
      "[193]\tvalidation_0-auc:0.92997\tvalidation_1-auc:0.82756\n",
      "[194]\tvalidation_0-auc:0.92988\tvalidation_1-auc:0.82777\n",
      "[195]\tvalidation_0-auc:0.93033\tvalidation_1-auc:0.82814\n",
      "[196]\tvalidation_0-auc:0.93056\tvalidation_1-auc:0.82800\n",
      "[197]\tvalidation_0-auc:0.93077\tvalidation_1-auc:0.82808\n",
      "[198]\tvalidation_0-auc:0.93085\tvalidation_1-auc:0.82818\n",
      "[199]\tvalidation_0-auc:0.93115\tvalidation_1-auc:0.82837\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(\n",
    "    n_estimators = int(best_01['n_estimator'])\n",
    "    , max_depth = int(best_01['max_depth'])\n",
    "    , learning_rate = best_01['learning_rate']\n",
    "    , subsample = best_01['subsample']\n",
    "    , closample_bytree = best_01['colsample_bytree']\n",
    "    , random_state = 42\n",
    "    , eval_metric = 'logloss'                       \n",
    ")\n",
    "\n",
    "eval_list = [(X_tr, y_tr), (X_val, y_val)]\n",
    "best_model.fit(X_tr\n",
    "               , y_tr\n",
    "               , early_stopping_rounds = 100\n",
    "               , eval_set = eval_list\n",
    "               , eval_metric = 'auc'\n",
    "               )\n",
    "\n",
    "wr_pred = best_model.predict(X_test)\n",
    "wr_pred_proba = best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 : 0.5030859399526705\n",
      "test2 : 0.8409906272124779\n"
     ]
    }
   ],
   "source": [
    "print(f'test1 : {roc_auc_score(y_test, wr_pred)}')\n",
    "print(f'test2 : {roc_auc_score(y_test, wr_pred_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6406824979336891,\n",
       " 'learning_rate': 0.12212214378271394,\n",
       " 'max_depth': 5.0,\n",
       " 'n_estimator': 230.0,\n",
       " 'subsample': 0.6796628299126117}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_probs=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(f'''\n",
    "          accuracy : {accuracy}\n",
    "          precision : {precision}\n",
    "          recall : {recall}\n",
    "          f1 : {f1}\n",
    "          roc_auc : {roc_auc}\n",
    "          ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.159747\tvalid_1's binary_logloss: 0.161487\n",
      "[2]\ttraining's binary_logloss: 0.155995\tvalid_1's binary_logloss: 0.158489\n",
      "[3]\ttraining's binary_logloss: 0.152875\tvalid_1's binary_logloss: 0.155925\n",
      "[4]\ttraining's binary_logloss: 0.150255\tvalid_1's binary_logloss: 0.153849\n",
      "[5]\ttraining's binary_logloss: 0.148052\tvalid_1's binary_logloss: 0.152054\n",
      "[6]\ttraining's binary_logloss: 0.146074\tvalid_1's binary_logloss: 0.1505\n",
      "[7]\ttraining's binary_logloss: 0.144325\tvalid_1's binary_logloss: 0.149162\n",
      "[8]\ttraining's binary_logloss: 0.142724\tvalid_1's binary_logloss: 0.14795\n",
      "[9]\ttraining's binary_logloss: 0.141297\tvalid_1's binary_logloss: 0.146862\n",
      "[10]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.145886\n",
      "[11]\ttraining's binary_logloss: 0.138763\tvalid_1's binary_logloss: 0.144993\n",
      "[12]\ttraining's binary_logloss: 0.137652\tvalid_1's binary_logloss: 0.14414\n",
      "[13]\ttraining's binary_logloss: 0.136616\tvalid_1's binary_logloss: 0.1434\n",
      "[14]\ttraining's binary_logloss: 0.135651\tvalid_1's binary_logloss: 0.142704\n",
      "[15]\ttraining's binary_logloss: 0.134786\tvalid_1's binary_logloss: 0.142119\n",
      "[16]\ttraining's binary_logloss: 0.13392\tvalid_1's binary_logloss: 0.141507\n",
      "[17]\ttraining's binary_logloss: 0.133095\tvalid_1's binary_logloss: 0.141041\n",
      "[18]\ttraining's binary_logloss: 0.132328\tvalid_1's binary_logloss: 0.140619\n",
      "[19]\ttraining's binary_logloss: 0.131665\tvalid_1's binary_logloss: 0.140197\n",
      "[20]\ttraining's binary_logloss: 0.131013\tvalid_1's binary_logloss: 0.139761\n",
      "[21]\ttraining's binary_logloss: 0.130344\tvalid_1's binary_logloss: 0.139332\n",
      "[22]\ttraining's binary_logloss: 0.129721\tvalid_1's binary_logloss: 0.138971\n",
      "[23]\ttraining's binary_logloss: 0.129159\tvalid_1's binary_logloss: 0.138647\n",
      "[24]\ttraining's binary_logloss: 0.128625\tvalid_1's binary_logloss: 0.138353\n",
      "[25]\ttraining's binary_logloss: 0.128103\tvalid_1's binary_logloss: 0.138153\n",
      "[26]\ttraining's binary_logloss: 0.127585\tvalid_1's binary_logloss: 0.137908\n",
      "[27]\ttraining's binary_logloss: 0.127107\tvalid_1's binary_logloss: 0.137726\n",
      "[28]\ttraining's binary_logloss: 0.126637\tvalid_1's binary_logloss: 0.137533\n",
      "[29]\ttraining's binary_logloss: 0.126183\tvalid_1's binary_logloss: 0.137354\n",
      "[30]\ttraining's binary_logloss: 0.125738\tvalid_1's binary_logloss: 0.137151\n",
      "[31]\ttraining's binary_logloss: 0.125293\tvalid_1's binary_logloss: 0.137\n",
      "[32]\ttraining's binary_logloss: 0.124867\tvalid_1's binary_logloss: 0.136828\n",
      "[33]\ttraining's binary_logloss: 0.124516\tvalid_1's binary_logloss: 0.136686\n",
      "[34]\ttraining's binary_logloss: 0.124158\tvalid_1's binary_logloss: 0.136544\n",
      "[35]\ttraining's binary_logloss: 0.12377\tvalid_1's binary_logloss: 0.136452\n",
      "[36]\ttraining's binary_logloss: 0.123426\tvalid_1's binary_logloss: 0.136348\n",
      "[37]\ttraining's binary_logloss: 0.123069\tvalid_1's binary_logloss: 0.136197\n",
      "[38]\ttraining's binary_logloss: 0.122696\tvalid_1's binary_logloss: 0.136108\n",
      "[39]\ttraining's binary_logloss: 0.122369\tvalid_1's binary_logloss: 0.13602\n",
      "[40]\ttraining's binary_logloss: 0.122066\tvalid_1's binary_logloss: 0.135936\n",
      "[41]\ttraining's binary_logloss: 0.121787\tvalid_1's binary_logloss: 0.135801\n",
      "[42]\ttraining's binary_logloss: 0.121475\tvalid_1's binary_logloss: 0.135725\n",
      "[43]\ttraining's binary_logloss: 0.121153\tvalid_1's binary_logloss: 0.135692\n",
      "[44]\ttraining's binary_logloss: 0.120861\tvalid_1's binary_logloss: 0.135575\n",
      "[45]\ttraining's binary_logloss: 0.12054\tvalid_1's binary_logloss: 0.135485\n",
      "[46]\ttraining's binary_logloss: 0.120258\tvalid_1's binary_logloss: 0.135446\n",
      "[47]\ttraining's binary_logloss: 0.119952\tvalid_1's binary_logloss: 0.135414\n",
      "[48]\ttraining's binary_logloss: 0.119684\tvalid_1's binary_logloss: 0.135391\n",
      "[49]\ttraining's binary_logloss: 0.119366\tvalid_1's binary_logloss: 0.135345\n",
      "[50]\ttraining's binary_logloss: 0.119136\tvalid_1's binary_logloss: 0.135296\n",
      "[51]\ttraining's binary_logloss: 0.118869\tvalid_1's binary_logloss: 0.13527\n",
      "[52]\ttraining's binary_logloss: 0.118628\tvalid_1's binary_logloss: 0.135213\n",
      "[53]\ttraining's binary_logloss: 0.118382\tvalid_1's binary_logloss: 0.135207\n",
      "[54]\ttraining's binary_logloss: 0.118134\tvalid_1's binary_logloss: 0.135149\n",
      "[55]\ttraining's binary_logloss: 0.117892\tvalid_1's binary_logloss: 0.135125\n",
      "[56]\ttraining's binary_logloss: 0.117657\tvalid_1's binary_logloss: 0.135067\n",
      "[57]\ttraining's binary_logloss: 0.117456\tvalid_1's binary_logloss: 0.13503\n",
      "[58]\ttraining's binary_logloss: 0.11721\tvalid_1's binary_logloss: 0.135023\n",
      "[59]\ttraining's binary_logloss: 0.11701\tvalid_1's binary_logloss: 0.134999\n",
      "[60]\ttraining's binary_logloss: 0.116778\tvalid_1's binary_logloss: 0.135007\n",
      "[61]\ttraining's binary_logloss: 0.116547\tvalid_1's binary_logloss: 0.134961\n",
      "[62]\ttraining's binary_logloss: 0.116334\tvalid_1's binary_logloss: 0.134924\n",
      "[63]\ttraining's binary_logloss: 0.116105\tvalid_1's binary_logloss: 0.134944\n",
      "[64]\ttraining's binary_logloss: 0.115904\tvalid_1's binary_logloss: 0.134897\n",
      "[65]\ttraining's binary_logloss: 0.115747\tvalid_1's binary_logloss: 0.134873\n",
      "[66]\ttraining's binary_logloss: 0.115552\tvalid_1's binary_logloss: 0.134877\n",
      "[67]\ttraining's binary_logloss: 0.115384\tvalid_1's binary_logloss: 0.13486\n",
      "[68]\ttraining's binary_logloss: 0.115165\tvalid_1's binary_logloss: 0.134824\n",
      "[69]\ttraining's binary_logloss: 0.114964\tvalid_1's binary_logloss: 0.134841\n",
      "[70]\ttraining's binary_logloss: 0.114778\tvalid_1's binary_logloss: 0.134871\n",
      "[71]\ttraining's binary_logloss: 0.114608\tvalid_1's binary_logloss: 0.134863\n",
      "[72]\ttraining's binary_logloss: 0.114414\tvalid_1's binary_logloss: 0.134845\n",
      "[73]\ttraining's binary_logloss: 0.114198\tvalid_1's binary_logloss: 0.134859\n",
      "[74]\ttraining's binary_logloss: 0.11402\tvalid_1's binary_logloss: 0.134851\n",
      "[75]\ttraining's binary_logloss: 0.113794\tvalid_1's binary_logloss: 0.134863\n",
      "[76]\ttraining's binary_logloss: 0.113652\tvalid_1's binary_logloss: 0.134829\n",
      "[77]\ttraining's binary_logloss: 0.113483\tvalid_1's binary_logloss: 0.134821\n",
      "[78]\ttraining's binary_logloss: 0.113292\tvalid_1's binary_logloss: 0.134828\n",
      "[79]\ttraining's binary_logloss: 0.113142\tvalid_1's binary_logloss: 0.134828\n",
      "[80]\ttraining's binary_logloss: 0.112989\tvalid_1's binary_logloss: 0.134777\n",
      "[81]\ttraining's binary_logloss: 0.112805\tvalid_1's binary_logloss: 0.13481\n",
      "[82]\ttraining's binary_logloss: 0.112665\tvalid_1's binary_logloss: 0.134787\n",
      "[83]\ttraining's binary_logloss: 0.112518\tvalid_1's binary_logloss: 0.134776\n",
      "[84]\ttraining's binary_logloss: 0.112369\tvalid_1's binary_logloss: 0.134742\n",
      "[85]\ttraining's binary_logloss: 0.11222\tvalid_1's binary_logloss: 0.134719\n",
      "[86]\ttraining's binary_logloss: 0.112089\tvalid_1's binary_logloss: 0.134711\n",
      "[87]\ttraining's binary_logloss: 0.111956\tvalid_1's binary_logloss: 0.134734\n",
      "[88]\ttraining's binary_logloss: 0.111785\tvalid_1's binary_logloss: 0.134752\n",
      "[89]\ttraining's binary_logloss: 0.111659\tvalid_1's binary_logloss: 0.134743\n",
      "[90]\ttraining's binary_logloss: 0.111473\tvalid_1's binary_logloss: 0.134725\n",
      "[91]\ttraining's binary_logloss: 0.111304\tvalid_1's binary_logloss: 0.134722\n",
      "[92]\ttraining's binary_logloss: 0.111154\tvalid_1's binary_logloss: 0.13476\n",
      "[93]\ttraining's binary_logloss: 0.11103\tvalid_1's binary_logloss: 0.134738\n",
      "[94]\ttraining's binary_logloss: 0.110871\tvalid_1's binary_logloss: 0.134735\n",
      "[95]\ttraining's binary_logloss: 0.110753\tvalid_1's binary_logloss: 0.134728\n",
      "[96]\ttraining's binary_logloss: 0.110633\tvalid_1's binary_logloss: 0.134709\n",
      "[97]\ttraining's binary_logloss: 0.110494\tvalid_1's binary_logloss: 0.134677\n",
      "[98]\ttraining's binary_logloss: 0.110349\tvalid_1's binary_logloss: 0.134701\n",
      "[99]\ttraining's binary_logloss: 0.110186\tvalid_1's binary_logloss: 0.134716\n",
      "[100]\ttraining's binary_logloss: 0.110065\tvalid_1's binary_logloss: 0.134704\n",
      "[101]\ttraining's binary_logloss: 0.109893\tvalid_1's binary_logloss: 0.134699\n",
      "[102]\ttraining's binary_logloss: 0.109786\tvalid_1's binary_logloss: 0.134724\n",
      "[103]\ttraining's binary_logloss: 0.109662\tvalid_1's binary_logloss: 0.134733\n",
      "[104]\ttraining's binary_logloss: 0.109563\tvalid_1's binary_logloss: 0.134745\n",
      "[105]\ttraining's binary_logloss: 0.109446\tvalid_1's binary_logloss: 0.13472\n",
      "[106]\ttraining's binary_logloss: 0.109314\tvalid_1's binary_logloss: 0.13473\n",
      "[107]\ttraining's binary_logloss: 0.109184\tvalid_1's binary_logloss: 0.134746\n",
      "[108]\ttraining's binary_logloss: 0.109062\tvalid_1's binary_logloss: 0.134767\n",
      "[109]\ttraining's binary_logloss: 0.10891\tvalid_1's binary_logloss: 0.134751\n",
      "[110]\ttraining's binary_logloss: 0.108782\tvalid_1's binary_logloss: 0.134785\n",
      "[111]\ttraining's binary_logloss: 0.108679\tvalid_1's binary_logloss: 0.134794\n",
      "[112]\ttraining's binary_logloss: 0.108576\tvalid_1's binary_logloss: 0.134794\n",
      "[113]\ttraining's binary_logloss: 0.108471\tvalid_1's binary_logloss: 0.134782\n",
      "[114]\ttraining's binary_logloss: 0.108374\tvalid_1's binary_logloss: 0.13478\n",
      "[115]\ttraining's binary_logloss: 0.108249\tvalid_1's binary_logloss: 0.13479\n",
      "[116]\ttraining's binary_logloss: 0.108098\tvalid_1's binary_logloss: 0.134811\n",
      "[117]\ttraining's binary_logloss: 0.107962\tvalid_1's binary_logloss: 0.1348\n",
      "[118]\ttraining's binary_logloss: 0.107858\tvalid_1's binary_logloss: 0.134818\n",
      "[119]\ttraining's binary_logloss: 0.107761\tvalid_1's binary_logloss: 0.134835\n",
      "[120]\ttraining's binary_logloss: 0.107683\tvalid_1's binary_logloss: 0.134841\n",
      "[121]\ttraining's binary_logloss: 0.107581\tvalid_1's binary_logloss: 0.134843\n",
      "[122]\ttraining's binary_logloss: 0.107426\tvalid_1's binary_logloss: 0.134887\n",
      "[123]\ttraining's binary_logloss: 0.107341\tvalid_1's binary_logloss: 0.134894\n",
      "[124]\ttraining's binary_logloss: 0.107256\tvalid_1's binary_logloss: 0.134916\n",
      "[125]\ttraining's binary_logloss: 0.107146\tvalid_1's binary_logloss: 0.134918\n",
      "[126]\ttraining's binary_logloss: 0.107053\tvalid_1's binary_logloss: 0.134923\n",
      "[127]\ttraining's binary_logloss: 0.106938\tvalid_1's binary_logloss: 0.134935\n",
      "[128]\ttraining's binary_logloss: 0.106844\tvalid_1's binary_logloss: 0.134946\n",
      "[129]\ttraining's binary_logloss: 0.106755\tvalid_1's binary_logloss: 0.13497\n",
      "[130]\ttraining's binary_logloss: 0.106578\tvalid_1's binary_logloss: 0.134992\n",
      "[131]\ttraining's binary_logloss: 0.106473\tvalid_1's binary_logloss: 0.134981\n",
      "[132]\ttraining's binary_logloss: 0.106391\tvalid_1's binary_logloss: 0.134966\n",
      "[133]\ttraining's binary_logloss: 0.106274\tvalid_1's binary_logloss: 0.134976\n",
      "[134]\ttraining's binary_logloss: 0.106194\tvalid_1's binary_logloss: 0.134978\n",
      "[135]\ttraining's binary_logloss: 0.106027\tvalid_1's binary_logloss: 0.135\n",
      "[136]\ttraining's binary_logloss: 0.105839\tvalid_1's binary_logloss: 0.135053\n",
      "[137]\ttraining's binary_logloss: 0.105669\tvalid_1's binary_logloss: 0.135072\n",
      "[138]\ttraining's binary_logloss: 0.105586\tvalid_1's binary_logloss: 0.135078\n",
      "[139]\ttraining's binary_logloss: 0.105509\tvalid_1's binary_logloss: 0.135085\n",
      "[140]\ttraining's binary_logloss: 0.105391\tvalid_1's binary_logloss: 0.135081\n",
      "[141]\ttraining's binary_logloss: 0.105278\tvalid_1's binary_logloss: 0.135107\n",
      "[142]\ttraining's binary_logloss: 0.105139\tvalid_1's binary_logloss: 0.135096\n",
      "[143]\ttraining's binary_logloss: 0.105048\tvalid_1's binary_logloss: 0.135094\n",
      "[144]\ttraining's binary_logloss: 0.104961\tvalid_1's binary_logloss: 0.135092\n",
      "[145]\ttraining's binary_logloss: 0.104888\tvalid_1's binary_logloss: 0.1351\n",
      "[146]\ttraining's binary_logloss: 0.104764\tvalid_1's binary_logloss: 0.135073\n",
      "[147]\ttraining's binary_logloss: 0.104699\tvalid_1's binary_logloss: 0.135078\n",
      "[[14565     5]\n",
      " [  630     4]]\n",
      "********************\n",
      "\n",
      "          accuracy : 0.9582346750855039\n",
      "          precision : 0.4444444444444444\n",
      "          recall : 0.006309148264984227\n",
      "          f1 : 0.012441679626749611\n",
      "          roc_auc : 0.5029829886829382\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "### LGBM 추가\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators= 400\n",
    "                            , learning_rate = 0.05)\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr\n",
    "                 , early_stopping_rounds=50\n",
    "                 , eval_metric = 'logloss'\n",
    "                 , eval_set = evals\n",
    "                 , verbose = True\n",
    "                 )\n",
    "\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403631765717119"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.163593\tvalid_1's binary_logloss: 0.164704\n",
      "[2]\ttraining's binary_logloss: 0.162662\tvalid_1's binary_logloss: 0.163935\n",
      "[3]\ttraining's binary_logloss: 0.16176\tvalid_1's binary_logloss: 0.163194\n",
      "[4]\ttraining's binary_logloss: 0.160905\tvalid_1's binary_logloss: 0.162479\n",
      "[5]\ttraining's binary_logloss: 0.160099\tvalid_1's binary_logloss: 0.161808\n",
      "[6]\ttraining's binary_logloss: 0.159329\tvalid_1's binary_logloss: 0.161157\n",
      "[7]\ttraining's binary_logloss: 0.158585\tvalid_1's binary_logloss: 0.160552\n",
      "[8]\ttraining's binary_logloss: 0.157878\tvalid_1's binary_logloss: 0.159974\n",
      "[9]\ttraining's binary_logloss: 0.157174\tvalid_1's binary_logloss: 0.159406\n",
      "[10]\ttraining's binary_logloss: 0.156491\tvalid_1's binary_logloss: 0.158849\n",
      "[11]\ttraining's binary_logloss: 0.15584\tvalid_1's binary_logloss: 0.158318\n",
      "[12]\ttraining's binary_logloss: 0.155221\tvalid_1's binary_logloss: 0.157809\n",
      "[13]\ttraining's binary_logloss: 0.154618\tvalid_1's binary_logloss: 0.157322\n",
      "[14]\ttraining's binary_logloss: 0.154037\tvalid_1's binary_logloss: 0.156843\n",
      "[15]\ttraining's binary_logloss: 0.153471\tvalid_1's binary_logloss: 0.156379\n",
      "[16]\ttraining's binary_logloss: 0.152925\tvalid_1's binary_logloss: 0.155955\n",
      "[17]\ttraining's binary_logloss: 0.152394\tvalid_1's binary_logloss: 0.155512\n",
      "[18]\ttraining's binary_logloss: 0.151874\tvalid_1's binary_logloss: 0.155101\n",
      "[19]\ttraining's binary_logloss: 0.151378\tvalid_1's binary_logloss: 0.154717\n",
      "[20]\ttraining's binary_logloss: 0.150892\tvalid_1's binary_logloss: 0.154317\n",
      "[21]\ttraining's binary_logloss: 0.150424\tvalid_1's binary_logloss: 0.153939\n",
      "[22]\ttraining's binary_logloss: 0.149955\tvalid_1's binary_logloss: 0.153564\n",
      "[23]\ttraining's binary_logloss: 0.149506\tvalid_1's binary_logloss: 0.153204\n",
      "[24]\ttraining's binary_logloss: 0.149067\tvalid_1's binary_logloss: 0.152854\n",
      "[25]\ttraining's binary_logloss: 0.14864\tvalid_1's binary_logloss: 0.152512\n",
      "[26]\ttraining's binary_logloss: 0.148225\tvalid_1's binary_logloss: 0.152177\n",
      "[27]\ttraining's binary_logloss: 0.147812\tvalid_1's binary_logloss: 0.151874\n",
      "[28]\ttraining's binary_logloss: 0.147419\tvalid_1's binary_logloss: 0.151574\n",
      "[29]\ttraining's binary_logloss: 0.147032\tvalid_1's binary_logloss: 0.151267\n",
      "[30]\ttraining's binary_logloss: 0.146657\tvalid_1's binary_logloss: 0.150975\n",
      "[31]\ttraining's binary_logloss: 0.14629\tvalid_1's binary_logloss: 0.15069\n",
      "[32]\ttraining's binary_logloss: 0.145921\tvalid_1's binary_logloss: 0.150407\n",
      "[33]\ttraining's binary_logloss: 0.14557\tvalid_1's binary_logloss: 0.150136\n",
      "[34]\ttraining's binary_logloss: 0.145216\tvalid_1's binary_logloss: 0.149868\n",
      "[35]\ttraining's binary_logloss: 0.144871\tvalid_1's binary_logloss: 0.149603\n",
      "[36]\ttraining's binary_logloss: 0.144538\tvalid_1's binary_logloss: 0.149339\n",
      "[37]\ttraining's binary_logloss: 0.144208\tvalid_1's binary_logloss: 0.149091\n",
      "[38]\ttraining's binary_logloss: 0.143889\tvalid_1's binary_logloss: 0.148845\n",
      "[39]\ttraining's binary_logloss: 0.143575\tvalid_1's binary_logloss: 0.14861\n",
      "[40]\ttraining's binary_logloss: 0.143273\tvalid_1's binary_logloss: 0.148379\n",
      "[41]\ttraining's binary_logloss: 0.142966\tvalid_1's binary_logloss: 0.148129\n",
      "[42]\ttraining's binary_logloss: 0.142664\tvalid_1's binary_logloss: 0.147893\n",
      "[43]\ttraining's binary_logloss: 0.142377\tvalid_1's binary_logloss: 0.147667\n",
      "[44]\ttraining's binary_logloss: 0.142084\tvalid_1's binary_logloss: 0.147441\n",
      "[45]\ttraining's binary_logloss: 0.141806\tvalid_1's binary_logloss: 0.147227\n",
      "[46]\ttraining's binary_logloss: 0.141531\tvalid_1's binary_logloss: 0.147014\n",
      "[47]\ttraining's binary_logloss: 0.141264\tvalid_1's binary_logloss: 0.146814\n",
      "[48]\ttraining's binary_logloss: 0.140998\tvalid_1's binary_logloss: 0.146622\n",
      "[49]\ttraining's binary_logloss: 0.14074\tvalid_1's binary_logloss: 0.146425\n",
      "[50]\ttraining's binary_logloss: 0.140482\tvalid_1's binary_logloss: 0.146213\n",
      "[51]\ttraining's binary_logloss: 0.140236\tvalid_1's binary_logloss: 0.146022\n",
      "[52]\ttraining's binary_logloss: 0.139981\tvalid_1's binary_logloss: 0.145839\n",
      "[53]\ttraining's binary_logloss: 0.139736\tvalid_1's binary_logloss: 0.145659\n",
      "[54]\ttraining's binary_logloss: 0.139496\tvalid_1's binary_logloss: 0.145474\n",
      "[55]\ttraining's binary_logloss: 0.13926\tvalid_1's binary_logloss: 0.145299\n",
      "[56]\ttraining's binary_logloss: 0.139024\tvalid_1's binary_logloss: 0.145121\n",
      "[57]\ttraining's binary_logloss: 0.138793\tvalid_1's binary_logloss: 0.144948\n",
      "[58]\ttraining's binary_logloss: 0.138567\tvalid_1's binary_logloss: 0.144784\n",
      "[59]\ttraining's binary_logloss: 0.138341\tvalid_1's binary_logloss: 0.144624\n",
      "[60]\ttraining's binary_logloss: 0.138127\tvalid_1's binary_logloss: 0.144461\n",
      "[61]\ttraining's binary_logloss: 0.137911\tvalid_1's binary_logloss: 0.144295\n",
      "[62]\ttraining's binary_logloss: 0.137692\tvalid_1's binary_logloss: 0.144135\n",
      "[63]\ttraining's binary_logloss: 0.137475\tvalid_1's binary_logloss: 0.143972\n",
      "[64]\ttraining's binary_logloss: 0.137268\tvalid_1's binary_logloss: 0.143825\n",
      "[65]\ttraining's binary_logloss: 0.137064\tvalid_1's binary_logloss: 0.143684\n",
      "[66]\ttraining's binary_logloss: 0.136865\tvalid_1's binary_logloss: 0.143538\n",
      "[67]\ttraining's binary_logloss: 0.136671\tvalid_1's binary_logloss: 0.1434\n",
      "[68]\ttraining's binary_logloss: 0.13648\tvalid_1's binary_logloss: 0.143266\n",
      "[69]\ttraining's binary_logloss: 0.136293\tvalid_1's binary_logloss: 0.143128\n",
      "[70]\ttraining's binary_logloss: 0.136095\tvalid_1's binary_logloss: 0.142994\n",
      "[71]\ttraining's binary_logloss: 0.135914\tvalid_1's binary_logloss: 0.142861\n",
      "[72]\ttraining's binary_logloss: 0.135726\tvalid_1's binary_logloss: 0.142725\n",
      "[73]\ttraining's binary_logloss: 0.135543\tvalid_1's binary_logloss: 0.142589\n",
      "[74]\ttraining's binary_logloss: 0.135368\tvalid_1's binary_logloss: 0.142465\n",
      "[75]\ttraining's binary_logloss: 0.135184\tvalid_1's binary_logloss: 0.142345\n",
      "[76]\ttraining's binary_logloss: 0.135008\tvalid_1's binary_logloss: 0.142227\n",
      "[77]\ttraining's binary_logloss: 0.134832\tvalid_1's binary_logloss: 0.142105\n",
      "[78]\ttraining's binary_logloss: 0.134656\tvalid_1's binary_logloss: 0.141985\n",
      "[79]\ttraining's binary_logloss: 0.134484\tvalid_1's binary_logloss: 0.141864\n",
      "[80]\ttraining's binary_logloss: 0.134318\tvalid_1's binary_logloss: 0.14176\n",
      "[81]\ttraining's binary_logloss: 0.134155\tvalid_1's binary_logloss: 0.141647\n",
      "[82]\ttraining's binary_logloss: 0.134001\tvalid_1's binary_logloss: 0.141538\n",
      "[83]\ttraining's binary_logloss: 0.13384\tvalid_1's binary_logloss: 0.141436\n",
      "[84]\ttraining's binary_logloss: 0.133681\tvalid_1's binary_logloss: 0.141339\n",
      "[85]\ttraining's binary_logloss: 0.133523\tvalid_1's binary_logloss: 0.14124\n",
      "[86]\ttraining's binary_logloss: 0.133364\tvalid_1's binary_logloss: 0.141144\n",
      "[87]\ttraining's binary_logloss: 0.133209\tvalid_1's binary_logloss: 0.14105\n",
      "[88]\ttraining's binary_logloss: 0.133058\tvalid_1's binary_logloss: 0.140955\n",
      "[89]\ttraining's binary_logloss: 0.13291\tvalid_1's binary_logloss: 0.140861\n",
      "[90]\ttraining's binary_logloss: 0.132763\tvalid_1's binary_logloss: 0.140776\n",
      "[91]\ttraining's binary_logloss: 0.132619\tvalid_1's binary_logloss: 0.140682\n",
      "[92]\ttraining's binary_logloss: 0.132478\tvalid_1's binary_logloss: 0.140598\n",
      "[93]\ttraining's binary_logloss: 0.132338\tvalid_1's binary_logloss: 0.140503\n",
      "[94]\ttraining's binary_logloss: 0.1322\tvalid_1's binary_logloss: 0.140416\n",
      "[95]\ttraining's binary_logloss: 0.132067\tvalid_1's binary_logloss: 0.140331\n",
      "[96]\ttraining's binary_logloss: 0.131934\tvalid_1's binary_logloss: 0.140247\n",
      "[97]\ttraining's binary_logloss: 0.131805\tvalid_1's binary_logloss: 0.140168\n",
      "[98]\ttraining's binary_logloss: 0.131668\tvalid_1's binary_logloss: 0.140083\n",
      "[99]\ttraining's binary_logloss: 0.131536\tvalid_1's binary_logloss: 0.140004\n",
      "[100]\ttraining's binary_logloss: 0.131406\tvalid_1's binary_logloss: 0.13992\n",
      "[101]\ttraining's binary_logloss: 0.131279\tvalid_1's binary_logloss: 0.139838\n",
      "[102]\ttraining's binary_logloss: 0.131146\tvalid_1's binary_logloss: 0.139751\n",
      "[103]\ttraining's binary_logloss: 0.13101\tvalid_1's binary_logloss: 0.139662\n",
      "[104]\ttraining's binary_logloss: 0.13088\tvalid_1's binary_logloss: 0.139576\n",
      "[105]\ttraining's binary_logloss: 0.130754\tvalid_1's binary_logloss: 0.139495\n",
      "[106]\ttraining's binary_logloss: 0.130624\tvalid_1's binary_logloss: 0.139419\n",
      "[107]\ttraining's binary_logloss: 0.130505\tvalid_1's binary_logloss: 0.139348\n",
      "[108]\ttraining's binary_logloss: 0.13038\tvalid_1's binary_logloss: 0.139263\n",
      "[109]\ttraining's binary_logloss: 0.130261\tvalid_1's binary_logloss: 0.139187\n",
      "[110]\ttraining's binary_logloss: 0.130135\tvalid_1's binary_logloss: 0.139113\n",
      "[111]\ttraining's binary_logloss: 0.130021\tvalid_1's binary_logloss: 0.139032\n",
      "[112]\ttraining's binary_logloss: 0.129906\tvalid_1's binary_logloss: 0.138957\n",
      "[113]\ttraining's binary_logloss: 0.129795\tvalid_1's binary_logloss: 0.138895\n",
      "[114]\ttraining's binary_logloss: 0.129683\tvalid_1's binary_logloss: 0.138828\n",
      "[115]\ttraining's binary_logloss: 0.129566\tvalid_1's binary_logloss: 0.138771\n",
      "[116]\ttraining's binary_logloss: 0.12945\tvalid_1's binary_logloss: 0.138719\n",
      "[117]\ttraining's binary_logloss: 0.129339\tvalid_1's binary_logloss: 0.138658\n",
      "[118]\ttraining's binary_logloss: 0.129225\tvalid_1's binary_logloss: 0.138598\n",
      "[119]\ttraining's binary_logloss: 0.129115\tvalid_1's binary_logloss: 0.138534\n",
      "[120]\ttraining's binary_logloss: 0.128986\tvalid_1's binary_logloss: 0.138479\n",
      "[121]\ttraining's binary_logloss: 0.128876\tvalid_1's binary_logloss: 0.138422\n",
      "[122]\ttraining's binary_logloss: 0.128755\tvalid_1's binary_logloss: 0.13837\n",
      "[123]\ttraining's binary_logloss: 0.128647\tvalid_1's binary_logloss: 0.138315\n",
      "[124]\ttraining's binary_logloss: 0.128537\tvalid_1's binary_logloss: 0.138261\n",
      "[125]\ttraining's binary_logloss: 0.128434\tvalid_1's binary_logloss: 0.138212\n",
      "[126]\ttraining's binary_logloss: 0.128333\tvalid_1's binary_logloss: 0.138164\n",
      "[127]\ttraining's binary_logloss: 0.128222\tvalid_1's binary_logloss: 0.138116\n",
      "[128]\ttraining's binary_logloss: 0.128125\tvalid_1's binary_logloss: 0.138062\n",
      "[129]\ttraining's binary_logloss: 0.128021\tvalid_1's binary_logloss: 0.138015\n",
      "[130]\ttraining's binary_logloss: 0.127926\tvalid_1's binary_logloss: 0.137968\n",
      "[131]\ttraining's binary_logloss: 0.127818\tvalid_1's binary_logloss: 0.137922\n",
      "[132]\ttraining's binary_logloss: 0.127713\tvalid_1's binary_logloss: 0.137879\n",
      "[133]\ttraining's binary_logloss: 0.127613\tvalid_1's binary_logloss: 0.137839\n",
      "[134]\ttraining's binary_logloss: 0.127514\tvalid_1's binary_logloss: 0.137797\n",
      "[135]\ttraining's binary_logloss: 0.127423\tvalid_1's binary_logloss: 0.137751\n",
      "[136]\ttraining's binary_logloss: 0.127325\tvalid_1's binary_logloss: 0.137714\n",
      "[137]\ttraining's binary_logloss: 0.12723\tvalid_1's binary_logloss: 0.137675\n",
      "[138]\ttraining's binary_logloss: 0.127138\tvalid_1's binary_logloss: 0.137638\n",
      "[139]\ttraining's binary_logloss: 0.12705\tvalid_1's binary_logloss: 0.137599\n",
      "[140]\ttraining's binary_logloss: 0.12696\tvalid_1's binary_logloss: 0.137559\n",
      "[141]\ttraining's binary_logloss: 0.12687\tvalid_1's binary_logloss: 0.137514\n",
      "[142]\ttraining's binary_logloss: 0.126786\tvalid_1's binary_logloss: 0.13747\n",
      "[143]\ttraining's binary_logloss: 0.1267\tvalid_1's binary_logloss: 0.137434\n",
      "[144]\ttraining's binary_logloss: 0.126615\tvalid_1's binary_logloss: 0.137394\n",
      "[145]\ttraining's binary_logloss: 0.126535\tvalid_1's binary_logloss: 0.137356\n",
      "[146]\ttraining's binary_logloss: 0.126444\tvalid_1's binary_logloss: 0.137331\n",
      "[147]\ttraining's binary_logloss: 0.126363\tvalid_1's binary_logloss: 0.137302\n",
      "[148]\ttraining's binary_logloss: 0.126282\tvalid_1's binary_logloss: 0.137268\n",
      "[149]\ttraining's binary_logloss: 0.126198\tvalid_1's binary_logloss: 0.137236\n",
      "[150]\ttraining's binary_logloss: 0.126108\tvalid_1's binary_logloss: 0.137207\n",
      "[151]\ttraining's binary_logloss: 0.12602\tvalid_1's binary_logloss: 0.13717\n",
      "[152]\ttraining's binary_logloss: 0.125927\tvalid_1's binary_logloss: 0.137139\n",
      "[153]\ttraining's binary_logloss: 0.125842\tvalid_1's binary_logloss: 0.137107\n",
      "[154]\ttraining's binary_logloss: 0.125763\tvalid_1's binary_logloss: 0.137075\n",
      "[155]\ttraining's binary_logloss: 0.125681\tvalid_1's binary_logloss: 0.137043\n",
      "[156]\ttraining's binary_logloss: 0.125592\tvalid_1's binary_logloss: 0.137014\n",
      "[157]\ttraining's binary_logloss: 0.125499\tvalid_1's binary_logloss: 0.136977\n",
      "[158]\ttraining's binary_logloss: 0.125419\tvalid_1's binary_logloss: 0.136947\n",
      "[159]\ttraining's binary_logloss: 0.12533\tvalid_1's binary_logloss: 0.136909\n",
      "[160]\ttraining's binary_logloss: 0.125246\tvalid_1's binary_logloss: 0.136876\n",
      "[161]\ttraining's binary_logloss: 0.125174\tvalid_1's binary_logloss: 0.13685\n",
      "[162]\ttraining's binary_logloss: 0.12509\tvalid_1's binary_logloss: 0.136822\n",
      "[163]\ttraining's binary_logloss: 0.125011\tvalid_1's binary_logloss: 0.136789\n",
      "[164]\ttraining's binary_logloss: 0.124933\tvalid_1's binary_logloss: 0.136759\n",
      "[165]\ttraining's binary_logloss: 0.12485\tvalid_1's binary_logloss: 0.136723\n",
      "[166]\ttraining's binary_logloss: 0.124775\tvalid_1's binary_logloss: 0.13669\n",
      "[167]\ttraining's binary_logloss: 0.124695\tvalid_1's binary_logloss: 0.136662\n",
      "[168]\ttraining's binary_logloss: 0.124621\tvalid_1's binary_logloss: 0.136627\n",
      "[169]\ttraining's binary_logloss: 0.124555\tvalid_1's binary_logloss: 0.136604\n",
      "[170]\ttraining's binary_logloss: 0.124479\tvalid_1's binary_logloss: 0.136579\n",
      "[171]\ttraining's binary_logloss: 0.124403\tvalid_1's binary_logloss: 0.136548\n",
      "[172]\ttraining's binary_logloss: 0.124333\tvalid_1's binary_logloss: 0.13652\n",
      "[173]\ttraining's binary_logloss: 0.124256\tvalid_1's binary_logloss: 0.136491\n",
      "[174]\ttraining's binary_logloss: 0.124178\tvalid_1's binary_logloss: 0.136466\n",
      "[175]\ttraining's binary_logloss: 0.124107\tvalid_1's binary_logloss: 0.136438\n",
      "[176]\ttraining's binary_logloss: 0.124029\tvalid_1's binary_logloss: 0.136415\n",
      "[177]\ttraining's binary_logloss: 0.123963\tvalid_1's binary_logloss: 0.136393\n",
      "[178]\ttraining's binary_logloss: 0.123896\tvalid_1's binary_logloss: 0.13637\n",
      "[179]\ttraining's binary_logloss: 0.123831\tvalid_1's binary_logloss: 0.136344\n",
      "[180]\ttraining's binary_logloss: 0.123769\tvalid_1's binary_logloss: 0.136323\n",
      "[181]\ttraining's binary_logloss: 0.1237\tvalid_1's binary_logloss: 0.1363\n",
      "[182]\ttraining's binary_logloss: 0.123618\tvalid_1's binary_logloss: 0.136281\n",
      "[183]\ttraining's binary_logloss: 0.123551\tvalid_1's binary_logloss: 0.136261\n",
      "[184]\ttraining's binary_logloss: 0.123472\tvalid_1's binary_logloss: 0.136239\n",
      "[185]\ttraining's binary_logloss: 0.123404\tvalid_1's binary_logloss: 0.136222\n",
      "[186]\ttraining's binary_logloss: 0.123327\tvalid_1's binary_logloss: 0.1362\n",
      "[187]\ttraining's binary_logloss: 0.123254\tvalid_1's binary_logloss: 0.136184\n",
      "[188]\ttraining's binary_logloss: 0.123179\tvalid_1's binary_logloss: 0.136167\n",
      "[189]\ttraining's binary_logloss: 0.123111\tvalid_1's binary_logloss: 0.136147\n",
      "[190]\ttraining's binary_logloss: 0.123043\tvalid_1's binary_logloss: 0.136125\n",
      "[191]\ttraining's binary_logloss: 0.12297\tvalid_1's binary_logloss: 0.136104\n",
      "[192]\ttraining's binary_logloss: 0.1229\tvalid_1's binary_logloss: 0.136086\n",
      "[193]\ttraining's binary_logloss: 0.122833\tvalid_1's binary_logloss: 0.136074\n",
      "[194]\ttraining's binary_logloss: 0.122762\tvalid_1's binary_logloss: 0.136057\n",
      "[195]\ttraining's binary_logloss: 0.122699\tvalid_1's binary_logloss: 0.136042\n",
      "[196]\ttraining's binary_logloss: 0.122626\tvalid_1's binary_logloss: 0.136025\n",
      "[197]\ttraining's binary_logloss: 0.122565\tvalid_1's binary_logloss: 0.136005\n",
      "[198]\ttraining's binary_logloss: 0.122501\tvalid_1's binary_logloss: 0.135987\n",
      "[199]\ttraining's binary_logloss: 0.122437\tvalid_1's binary_logloss: 0.135967\n",
      "[200]\ttraining's binary_logloss: 0.12237\tvalid_1's binary_logloss: 0.13595\n",
      "[201]\ttraining's binary_logloss: 0.122302\tvalid_1's binary_logloss: 0.135936\n",
      "[202]\ttraining's binary_logloss: 0.122235\tvalid_1's binary_logloss: 0.135922\n",
      "[203]\ttraining's binary_logloss: 0.122175\tvalid_1's binary_logloss: 0.135908\n",
      "[204]\ttraining's binary_logloss: 0.122114\tvalid_1's binary_logloss: 0.135892\n",
      "[205]\ttraining's binary_logloss: 0.122053\tvalid_1's binary_logloss: 0.135874\n",
      "[206]\ttraining's binary_logloss: 0.121989\tvalid_1's binary_logloss: 0.135856\n",
      "[207]\ttraining's binary_logloss: 0.121927\tvalid_1's binary_logloss: 0.135842\n",
      "[208]\ttraining's binary_logloss: 0.121868\tvalid_1's binary_logloss: 0.135826\n",
      "[209]\ttraining's binary_logloss: 0.121802\tvalid_1's binary_logloss: 0.135816\n",
      "[210]\ttraining's binary_logloss: 0.121748\tvalid_1's binary_logloss: 0.135794\n",
      "[211]\ttraining's binary_logloss: 0.121685\tvalid_1's binary_logloss: 0.135781\n",
      "[212]\ttraining's binary_logloss: 0.12162\tvalid_1's binary_logloss: 0.135764\n",
      "[213]\ttraining's binary_logloss: 0.121557\tvalid_1's binary_logloss: 0.135756\n",
      "[214]\ttraining's binary_logloss: 0.121489\tvalid_1's binary_logloss: 0.135742\n",
      "[215]\ttraining's binary_logloss: 0.121426\tvalid_1's binary_logloss: 0.135732\n",
      "[216]\ttraining's binary_logloss: 0.12136\tvalid_1's binary_logloss: 0.135717\n",
      "[217]\ttraining's binary_logloss: 0.1213\tvalid_1's binary_logloss: 0.135697\n",
      "[218]\ttraining's binary_logloss: 0.121247\tvalid_1's binary_logloss: 0.135675\n",
      "[219]\ttraining's binary_logloss: 0.121189\tvalid_1's binary_logloss: 0.135661\n",
      "[220]\ttraining's binary_logloss: 0.121129\tvalid_1's binary_logloss: 0.135653\n",
      "[221]\ttraining's binary_logloss: 0.12107\tvalid_1's binary_logloss: 0.135632\n",
      "[222]\ttraining's binary_logloss: 0.121\tvalid_1's binary_logloss: 0.135614\n",
      "[223]\ttraining's binary_logloss: 0.120943\tvalid_1's binary_logloss: 0.135606\n",
      "[224]\ttraining's binary_logloss: 0.120877\tvalid_1's binary_logloss: 0.135589\n",
      "[225]\ttraining's binary_logloss: 0.120815\tvalid_1's binary_logloss: 0.135571\n",
      "[226]\ttraining's binary_logloss: 0.120754\tvalid_1's binary_logloss: 0.135564\n",
      "[227]\ttraining's binary_logloss: 0.120695\tvalid_1's binary_logloss: 0.135558\n",
      "[228]\ttraining's binary_logloss: 0.120639\tvalid_1's binary_logloss: 0.135552\n",
      "[229]\ttraining's binary_logloss: 0.120581\tvalid_1's binary_logloss: 0.135534\n",
      "[230]\ttraining's binary_logloss: 0.120529\tvalid_1's binary_logloss: 0.135524\n",
      "[231]\ttraining's binary_logloss: 0.120479\tvalid_1's binary_logloss: 0.135508\n",
      "[232]\ttraining's binary_logloss: 0.120427\tvalid_1's binary_logloss: 0.135498\n",
      "[233]\ttraining's binary_logloss: 0.120373\tvalid_1's binary_logloss: 0.135493\n",
      "[234]\ttraining's binary_logloss: 0.120322\tvalid_1's binary_logloss: 0.135482\n",
      "[235]\ttraining's binary_logloss: 0.120261\tvalid_1's binary_logloss: 0.135467\n",
      "[236]\ttraining's binary_logloss: 0.120207\tvalid_1's binary_logloss: 0.135448\n",
      "[237]\ttraining's binary_logloss: 0.120157\tvalid_1's binary_logloss: 0.135438\n",
      "[238]\ttraining's binary_logloss: 0.120103\tvalid_1's binary_logloss: 0.135431\n",
      "[239]\ttraining's binary_logloss: 0.120057\tvalid_1's binary_logloss: 0.135425\n",
      "[240]\ttraining's binary_logloss: 0.12001\tvalid_1's binary_logloss: 0.135409\n",
      "[241]\ttraining's binary_logloss: 0.119959\tvalid_1's binary_logloss: 0.135402\n",
      "[242]\ttraining's binary_logloss: 0.11991\tvalid_1's binary_logloss: 0.135392\n",
      "[243]\ttraining's binary_logloss: 0.11986\tvalid_1's binary_logloss: 0.135381\n",
      "[244]\ttraining's binary_logloss: 0.119793\tvalid_1's binary_logloss: 0.135366\n",
      "[245]\ttraining's binary_logloss: 0.119745\tvalid_1's binary_logloss: 0.135357\n",
      "[246]\ttraining's binary_logloss: 0.119695\tvalid_1's binary_logloss: 0.135354\n",
      "[247]\ttraining's binary_logloss: 0.119645\tvalid_1's binary_logloss: 0.135341\n",
      "[248]\ttraining's binary_logloss: 0.119597\tvalid_1's binary_logloss: 0.135333\n",
      "[249]\ttraining's binary_logloss: 0.119547\tvalid_1's binary_logloss: 0.135323\n",
      "[250]\ttraining's binary_logloss: 0.1195\tvalid_1's binary_logloss: 0.135321\n",
      "[251]\ttraining's binary_logloss: 0.119451\tvalid_1's binary_logloss: 0.135304\n",
      "[252]\ttraining's binary_logloss: 0.119405\tvalid_1's binary_logloss: 0.135301\n",
      "[253]\ttraining's binary_logloss: 0.119361\tvalid_1's binary_logloss: 0.135291\n",
      "[254]\ttraining's binary_logloss: 0.119316\tvalid_1's binary_logloss: 0.135285\n",
      "[255]\ttraining's binary_logloss: 0.119261\tvalid_1's binary_logloss: 0.135276\n",
      "[256]\ttraining's binary_logloss: 0.11921\tvalid_1's binary_logloss: 0.135277\n",
      "[257]\ttraining's binary_logloss: 0.119159\tvalid_1's binary_logloss: 0.135275\n",
      "[258]\ttraining's binary_logloss: 0.119109\tvalid_1's binary_logloss: 0.135258\n",
      "[259]\ttraining's binary_logloss: 0.11906\tvalid_1's binary_logloss: 0.13526\n",
      "[260]\ttraining's binary_logloss: 0.119014\tvalid_1's binary_logloss: 0.135252\n",
      "[261]\ttraining's binary_logloss: 0.118969\tvalid_1's binary_logloss: 0.135246\n",
      "[262]\ttraining's binary_logloss: 0.118923\tvalid_1's binary_logloss: 0.135248\n",
      "[263]\ttraining's binary_logloss: 0.118866\tvalid_1's binary_logloss: 0.135249\n",
      "[264]\ttraining's binary_logloss: 0.118822\tvalid_1's binary_logloss: 0.135233\n",
      "[265]\ttraining's binary_logloss: 0.11878\tvalid_1's binary_logloss: 0.135225\n",
      "[266]\ttraining's binary_logloss: 0.118726\tvalid_1's binary_logloss: 0.135214\n",
      "[267]\ttraining's binary_logloss: 0.118682\tvalid_1's binary_logloss: 0.135211\n",
      "[268]\ttraining's binary_logloss: 0.118629\tvalid_1's binary_logloss: 0.13521\n",
      "[269]\ttraining's binary_logloss: 0.118577\tvalid_1's binary_logloss: 0.135205\n",
      "[270]\ttraining's binary_logloss: 0.118526\tvalid_1's binary_logloss: 0.1352\n",
      "[271]\ttraining's binary_logloss: 0.118473\tvalid_1's binary_logloss: 0.135196\n",
      "[272]\ttraining's binary_logloss: 0.118425\tvalid_1's binary_logloss: 0.135196\n",
      "[273]\ttraining's binary_logloss: 0.118375\tvalid_1's binary_logloss: 0.135192\n",
      "[274]\ttraining's binary_logloss: 0.118328\tvalid_1's binary_logloss: 0.135182\n",
      "[275]\ttraining's binary_logloss: 0.118285\tvalid_1's binary_logloss: 0.135172\n",
      "[276]\ttraining's binary_logloss: 0.118239\tvalid_1's binary_logloss: 0.135173\n",
      "[277]\ttraining's binary_logloss: 0.118187\tvalid_1's binary_logloss: 0.135169\n",
      "[278]\ttraining's binary_logloss: 0.118145\tvalid_1's binary_logloss: 0.135164\n",
      "[279]\ttraining's binary_logloss: 0.118101\tvalid_1's binary_logloss: 0.13516\n",
      "[280]\ttraining's binary_logloss: 0.118059\tvalid_1's binary_logloss: 0.135151\n",
      "[281]\ttraining's binary_logloss: 0.118011\tvalid_1's binary_logloss: 0.135144\n",
      "[282]\ttraining's binary_logloss: 0.117968\tvalid_1's binary_logloss: 0.135142\n",
      "[283]\ttraining's binary_logloss: 0.117921\tvalid_1's binary_logloss: 0.135133\n",
      "[284]\ttraining's binary_logloss: 0.117871\tvalid_1's binary_logloss: 0.135129\n",
      "[285]\ttraining's binary_logloss: 0.117826\tvalid_1's binary_logloss: 0.135124\n",
      "[286]\ttraining's binary_logloss: 0.11778\tvalid_1's binary_logloss: 0.13512\n",
      "[287]\ttraining's binary_logloss: 0.117735\tvalid_1's binary_logloss: 0.135121\n",
      "[288]\ttraining's binary_logloss: 0.117687\tvalid_1's binary_logloss: 0.135108\n",
      "[289]\ttraining's binary_logloss: 0.117646\tvalid_1's binary_logloss: 0.1351\n",
      "[290]\ttraining's binary_logloss: 0.117597\tvalid_1's binary_logloss: 0.135104\n",
      "[291]\ttraining's binary_logloss: 0.117552\tvalid_1's binary_logloss: 0.135087\n",
      "[292]\ttraining's binary_logloss: 0.117511\tvalid_1's binary_logloss: 0.13508\n",
      "[293]\ttraining's binary_logloss: 0.117464\tvalid_1's binary_logloss: 0.135075\n",
      "[294]\ttraining's binary_logloss: 0.117422\tvalid_1's binary_logloss: 0.13506\n",
      "[295]\ttraining's binary_logloss: 0.117378\tvalid_1's binary_logloss: 0.135056\n",
      "[296]\ttraining's binary_logloss: 0.117342\tvalid_1's binary_logloss: 0.135052\n",
      "[297]\ttraining's binary_logloss: 0.1173\tvalid_1's binary_logloss: 0.135048\n",
      "[298]\ttraining's binary_logloss: 0.11726\tvalid_1's binary_logloss: 0.135041\n",
      "[299]\ttraining's binary_logloss: 0.117217\tvalid_1's binary_logloss: 0.13504\n",
      "[300]\ttraining's binary_logloss: 0.117179\tvalid_1's binary_logloss: 0.135037\n",
      "[301]\ttraining's binary_logloss: 0.11714\tvalid_1's binary_logloss: 0.135029\n",
      "[302]\ttraining's binary_logloss: 0.117101\tvalid_1's binary_logloss: 0.135029\n",
      "[303]\ttraining's binary_logloss: 0.11706\tvalid_1's binary_logloss: 0.135026\n",
      "[304]\ttraining's binary_logloss: 0.117015\tvalid_1's binary_logloss: 0.13503\n",
      "[305]\ttraining's binary_logloss: 0.116978\tvalid_1's binary_logloss: 0.135025\n",
      "[306]\ttraining's binary_logloss: 0.116941\tvalid_1's binary_logloss: 0.13502\n",
      "[307]\ttraining's binary_logloss: 0.116898\tvalid_1's binary_logloss: 0.135017\n",
      "[308]\ttraining's binary_logloss: 0.116857\tvalid_1's binary_logloss: 0.135017\n",
      "[309]\ttraining's binary_logloss: 0.116816\tvalid_1's binary_logloss: 0.135016\n",
      "[310]\ttraining's binary_logloss: 0.116775\tvalid_1's binary_logloss: 0.135012\n",
      "[311]\ttraining's binary_logloss: 0.116738\tvalid_1's binary_logloss: 0.13501\n",
      "[312]\ttraining's binary_logloss: 0.116693\tvalid_1's binary_logloss: 0.135018\n",
      "[313]\ttraining's binary_logloss: 0.116654\tvalid_1's binary_logloss: 0.13502\n",
      "[314]\ttraining's binary_logloss: 0.116619\tvalid_1's binary_logloss: 0.135015\n",
      "[315]\ttraining's binary_logloss: 0.116576\tvalid_1's binary_logloss: 0.13501\n",
      "[316]\ttraining's binary_logloss: 0.116528\tvalid_1's binary_logloss: 0.13501\n",
      "[317]\ttraining's binary_logloss: 0.116491\tvalid_1's binary_logloss: 0.135007\n",
      "[318]\ttraining's binary_logloss: 0.116457\tvalid_1's binary_logloss: 0.135004\n",
      "[319]\ttraining's binary_logloss: 0.116411\tvalid_1's binary_logloss: 0.135003\n",
      "[320]\ttraining's binary_logloss: 0.116377\tvalid_1's binary_logloss: 0.135001\n",
      "[321]\ttraining's binary_logloss: 0.116334\tvalid_1's binary_logloss: 0.135\n",
      "[322]\ttraining's binary_logloss: 0.116298\tvalid_1's binary_logloss: 0.134996\n",
      "[323]\ttraining's binary_logloss: 0.116261\tvalid_1's binary_logloss: 0.134998\n",
      "[324]\ttraining's binary_logloss: 0.116225\tvalid_1's binary_logloss: 0.134997\n",
      "[325]\ttraining's binary_logloss: 0.11619\tvalid_1's binary_logloss: 0.134996\n",
      "[326]\ttraining's binary_logloss: 0.116129\tvalid_1's binary_logloss: 0.134995\n",
      "[327]\ttraining's binary_logloss: 0.116096\tvalid_1's binary_logloss: 0.134996\n",
      "[328]\ttraining's binary_logloss: 0.116046\tvalid_1's binary_logloss: 0.134992\n",
      "[329]\ttraining's binary_logloss: 0.116014\tvalid_1's binary_logloss: 0.134993\n",
      "[330]\ttraining's binary_logloss: 0.115965\tvalid_1's binary_logloss: 0.134992\n",
      "[331]\ttraining's binary_logloss: 0.11593\tvalid_1's binary_logloss: 0.134993\n",
      "[332]\ttraining's binary_logloss: 0.115892\tvalid_1's binary_logloss: 0.134996\n",
      "[333]\ttraining's binary_logloss: 0.115851\tvalid_1's binary_logloss: 0.135004\n",
      "[334]\ttraining's binary_logloss: 0.115797\tvalid_1's binary_logloss: 0.134999\n",
      "[335]\ttraining's binary_logloss: 0.115768\tvalid_1's binary_logloss: 0.134995\n",
      "[336]\ttraining's binary_logloss: 0.115737\tvalid_1's binary_logloss: 0.134995\n",
      "[337]\ttraining's binary_logloss: 0.115689\tvalid_1's binary_logloss: 0.134991\n",
      "[338]\ttraining's binary_logloss: 0.11565\tvalid_1's binary_logloss: 0.134998\n",
      "[339]\ttraining's binary_logloss: 0.115602\tvalid_1's binary_logloss: 0.135\n",
      "[340]\ttraining's binary_logloss: 0.115572\tvalid_1's binary_logloss: 0.134998\n",
      "[341]\ttraining's binary_logloss: 0.115526\tvalid_1's binary_logloss: 0.135002\n",
      "[342]\ttraining's binary_logloss: 0.115494\tvalid_1's binary_logloss: 0.134994\n",
      "[343]\ttraining's binary_logloss: 0.115453\tvalid_1's binary_logloss: 0.134995\n",
      "[344]\ttraining's binary_logloss: 0.115415\tvalid_1's binary_logloss: 0.135003\n",
      "[345]\ttraining's binary_logloss: 0.115369\tvalid_1's binary_logloss: 0.135002\n",
      "[346]\ttraining's binary_logloss: 0.115344\tvalid_1's binary_logloss: 0.134999\n",
      "[347]\ttraining's binary_logloss: 0.115304\tvalid_1's binary_logloss: 0.135001\n",
      "[348]\ttraining's binary_logloss: 0.115267\tvalid_1's binary_logloss: 0.135\n",
      "[349]\ttraining's binary_logloss: 0.115223\tvalid_1's binary_logloss: 0.135003\n",
      "[350]\ttraining's binary_logloss: 0.115177\tvalid_1's binary_logloss: 0.134998\n",
      "[351]\ttraining's binary_logloss: 0.115146\tvalid_1's binary_logloss: 0.134988\n",
      "[352]\ttraining's binary_logloss: 0.115106\tvalid_1's binary_logloss: 0.134989\n",
      "[353]\ttraining's binary_logloss: 0.115067\tvalid_1's binary_logloss: 0.13499\n",
      "[354]\ttraining's binary_logloss: 0.115035\tvalid_1's binary_logloss: 0.134986\n",
      "[355]\ttraining's binary_logloss: 0.114993\tvalid_1's binary_logloss: 0.134983\n",
      "[356]\ttraining's binary_logloss: 0.114967\tvalid_1's binary_logloss: 0.134976\n",
      "[357]\ttraining's binary_logloss: 0.114925\tvalid_1's binary_logloss: 0.134971\n",
      "[358]\ttraining's binary_logloss: 0.114885\tvalid_1's binary_logloss: 0.134967\n",
      "[359]\ttraining's binary_logloss: 0.114851\tvalid_1's binary_logloss: 0.134966\n",
      "[360]\ttraining's binary_logloss: 0.114816\tvalid_1's binary_logloss: 0.134968\n",
      "[361]\ttraining's binary_logloss: 0.114786\tvalid_1's binary_logloss: 0.134963\n",
      "[362]\ttraining's binary_logloss: 0.114743\tvalid_1's binary_logloss: 0.134956\n",
      "[363]\ttraining's binary_logloss: 0.114707\tvalid_1's binary_logloss: 0.134959\n",
      "[364]\ttraining's binary_logloss: 0.114665\tvalid_1's binary_logloss: 0.134955\n",
      "[365]\ttraining's binary_logloss: 0.11463\tvalid_1's binary_logloss: 0.134955\n",
      "[366]\ttraining's binary_logloss: 0.114595\tvalid_1's binary_logloss: 0.134958\n",
      "[367]\ttraining's binary_logloss: 0.114559\tvalid_1's binary_logloss: 0.134958\n",
      "[368]\ttraining's binary_logloss: 0.114522\tvalid_1's binary_logloss: 0.134955\n",
      "[369]\ttraining's binary_logloss: 0.114489\tvalid_1's binary_logloss: 0.134959\n",
      "[370]\ttraining's binary_logloss: 0.114449\tvalid_1's binary_logloss: 0.134958\n",
      "[371]\ttraining's binary_logloss: 0.114422\tvalid_1's binary_logloss: 0.134957\n",
      "[372]\ttraining's binary_logloss: 0.114385\tvalid_1's binary_logloss: 0.134958\n",
      "[373]\ttraining's binary_logloss: 0.114347\tvalid_1's binary_logloss: 0.134954\n",
      "[374]\ttraining's binary_logloss: 0.114312\tvalid_1's binary_logloss: 0.134952\n",
      "[375]\ttraining's binary_logloss: 0.114279\tvalid_1's binary_logloss: 0.134956\n",
      "[376]\ttraining's binary_logloss: 0.114242\tvalid_1's binary_logloss: 0.134955\n",
      "[377]\ttraining's binary_logloss: 0.114215\tvalid_1's binary_logloss: 0.134952\n",
      "[378]\ttraining's binary_logloss: 0.114181\tvalid_1's binary_logloss: 0.134955\n",
      "[379]\ttraining's binary_logloss: 0.114149\tvalid_1's binary_logloss: 0.134957\n",
      "[380]\ttraining's binary_logloss: 0.114119\tvalid_1's binary_logloss: 0.134956\n",
      "[381]\ttraining's binary_logloss: 0.114079\tvalid_1's binary_logloss: 0.134957\n",
      "[382]\ttraining's binary_logloss: 0.114056\tvalid_1's binary_logloss: 0.134957\n",
      "[383]\ttraining's binary_logloss: 0.114015\tvalid_1's binary_logloss: 0.134964\n",
      "[384]\ttraining's binary_logloss: 0.113972\tvalid_1's binary_logloss: 0.13496\n",
      "[385]\ttraining's binary_logloss: 0.113941\tvalid_1's binary_logloss: 0.134955\n",
      "[386]\ttraining's binary_logloss: 0.113905\tvalid_1's binary_logloss: 0.134951\n",
      "[387]\ttraining's binary_logloss: 0.113876\tvalid_1's binary_logloss: 0.134948\n",
      "[388]\ttraining's binary_logloss: 0.113845\tvalid_1's binary_logloss: 0.13495\n",
      "[389]\ttraining's binary_logloss: 0.113814\tvalid_1's binary_logloss: 0.134956\n",
      "[390]\ttraining's binary_logloss: 0.113777\tvalid_1's binary_logloss: 0.134956\n",
      "[391]\ttraining's binary_logloss: 0.113744\tvalid_1's binary_logloss: 0.134954\n",
      "[392]\ttraining's binary_logloss: 0.113714\tvalid_1's binary_logloss: 0.134953\n",
      "[393]\ttraining's binary_logloss: 0.113688\tvalid_1's binary_logloss: 0.134953\n",
      "[394]\ttraining's binary_logloss: 0.113652\tvalid_1's binary_logloss: 0.134946\n",
      "[395]\ttraining's binary_logloss: 0.113613\tvalid_1's binary_logloss: 0.134947\n",
      "[396]\ttraining's binary_logloss: 0.113575\tvalid_1's binary_logloss: 0.134955\n",
      "[397]\ttraining's binary_logloss: 0.113541\tvalid_1's binary_logloss: 0.134951\n",
      "[398]\ttraining's binary_logloss: 0.113503\tvalid_1's binary_logloss: 0.13495\n",
      "[399]\ttraining's binary_logloss: 0.113466\tvalid_1's binary_logloss: 0.134954\n",
      "[400]\ttraining's binary_logloss: 0.113435\tvalid_1's binary_logloss: 0.13495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8401193845007999"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LGBM 추가\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators= 400\n",
    "                            , learning_rate = 0.01)\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr\n",
    "                 , early_stopping_rounds=50\n",
    "                 , eval_metric = 'logloss'\n",
    "                 , eval_set = evals\n",
    "                 , verbose = True\n",
    "                 )\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.163593\tvalid_1's binary_logloss: 0.164704\n",
      "[2]\ttraining's binary_logloss: 0.162662\tvalid_1's binary_logloss: 0.163935\n",
      "[3]\ttraining's binary_logloss: 0.16176\tvalid_1's binary_logloss: 0.163194\n",
      "[4]\ttraining's binary_logloss: 0.160905\tvalid_1's binary_logloss: 0.162479\n",
      "[5]\ttraining's binary_logloss: 0.160099\tvalid_1's binary_logloss: 0.161808\n",
      "[6]\ttraining's binary_logloss: 0.159329\tvalid_1's binary_logloss: 0.161157\n",
      "[7]\ttraining's binary_logloss: 0.158585\tvalid_1's binary_logloss: 0.160552\n",
      "[8]\ttraining's binary_logloss: 0.157878\tvalid_1's binary_logloss: 0.159974\n",
      "[9]\ttraining's binary_logloss: 0.157174\tvalid_1's binary_logloss: 0.159406\n",
      "[10]\ttraining's binary_logloss: 0.156491\tvalid_1's binary_logloss: 0.158849\n",
      "[11]\ttraining's binary_logloss: 0.15584\tvalid_1's binary_logloss: 0.158318\n",
      "[12]\ttraining's binary_logloss: 0.155221\tvalid_1's binary_logloss: 0.157809\n",
      "[13]\ttraining's binary_logloss: 0.154618\tvalid_1's binary_logloss: 0.157322\n",
      "[14]\ttraining's binary_logloss: 0.154037\tvalid_1's binary_logloss: 0.156843\n",
      "[15]\ttraining's binary_logloss: 0.153471\tvalid_1's binary_logloss: 0.156379\n",
      "[16]\ttraining's binary_logloss: 0.152925\tvalid_1's binary_logloss: 0.155955\n",
      "[17]\ttraining's binary_logloss: 0.152394\tvalid_1's binary_logloss: 0.155512\n",
      "[18]\ttraining's binary_logloss: 0.151874\tvalid_1's binary_logloss: 0.155101\n",
      "[19]\ttraining's binary_logloss: 0.151378\tvalid_1's binary_logloss: 0.154717\n",
      "[20]\ttraining's binary_logloss: 0.150892\tvalid_1's binary_logloss: 0.154317\n",
      "[21]\ttraining's binary_logloss: 0.150424\tvalid_1's binary_logloss: 0.153939\n",
      "[22]\ttraining's binary_logloss: 0.149955\tvalid_1's binary_logloss: 0.153564\n",
      "[23]\ttraining's binary_logloss: 0.149506\tvalid_1's binary_logloss: 0.153204\n",
      "[24]\ttraining's binary_logloss: 0.149067\tvalid_1's binary_logloss: 0.152854\n",
      "[25]\ttraining's binary_logloss: 0.14864\tvalid_1's binary_logloss: 0.152512\n",
      "[26]\ttraining's binary_logloss: 0.148225\tvalid_1's binary_logloss: 0.152177\n",
      "[27]\ttraining's binary_logloss: 0.147812\tvalid_1's binary_logloss: 0.151874\n",
      "[28]\ttraining's binary_logloss: 0.147419\tvalid_1's binary_logloss: 0.151574\n",
      "[29]\ttraining's binary_logloss: 0.147032\tvalid_1's binary_logloss: 0.151267\n",
      "[30]\ttraining's binary_logloss: 0.146657\tvalid_1's binary_logloss: 0.150975\n",
      "[31]\ttraining's binary_logloss: 0.14629\tvalid_1's binary_logloss: 0.15069\n",
      "[32]\ttraining's binary_logloss: 0.145921\tvalid_1's binary_logloss: 0.150407\n",
      "[33]\ttraining's binary_logloss: 0.14557\tvalid_1's binary_logloss: 0.150136\n",
      "[34]\ttraining's binary_logloss: 0.145216\tvalid_1's binary_logloss: 0.149868\n",
      "[35]\ttraining's binary_logloss: 0.144871\tvalid_1's binary_logloss: 0.149603\n",
      "[36]\ttraining's binary_logloss: 0.144538\tvalid_1's binary_logloss: 0.149339\n",
      "[37]\ttraining's binary_logloss: 0.144208\tvalid_1's binary_logloss: 0.149091\n",
      "[38]\ttraining's binary_logloss: 0.143889\tvalid_1's binary_logloss: 0.148845\n",
      "[39]\ttraining's binary_logloss: 0.143575\tvalid_1's binary_logloss: 0.14861\n",
      "[40]\ttraining's binary_logloss: 0.143273\tvalid_1's binary_logloss: 0.148379\n",
      "[41]\ttraining's binary_logloss: 0.142966\tvalid_1's binary_logloss: 0.148129\n",
      "[42]\ttraining's binary_logloss: 0.142664\tvalid_1's binary_logloss: 0.147893\n",
      "[43]\ttraining's binary_logloss: 0.142377\tvalid_1's binary_logloss: 0.147667\n",
      "[44]\ttraining's binary_logloss: 0.142084\tvalid_1's binary_logloss: 0.147441\n",
      "[45]\ttraining's binary_logloss: 0.141806\tvalid_1's binary_logloss: 0.147227\n",
      "[46]\ttraining's binary_logloss: 0.141531\tvalid_1's binary_logloss: 0.147014\n",
      "[47]\ttraining's binary_logloss: 0.141264\tvalid_1's binary_logloss: 0.146814\n",
      "[48]\ttraining's binary_logloss: 0.140998\tvalid_1's binary_logloss: 0.146622\n",
      "[49]\ttraining's binary_logloss: 0.14074\tvalid_1's binary_logloss: 0.146425\n",
      "[50]\ttraining's binary_logloss: 0.140482\tvalid_1's binary_logloss: 0.146213\n",
      "[51]\ttraining's binary_logloss: 0.140236\tvalid_1's binary_logloss: 0.146022\n",
      "[52]\ttraining's binary_logloss: 0.139981\tvalid_1's binary_logloss: 0.145839\n",
      "[53]\ttraining's binary_logloss: 0.139736\tvalid_1's binary_logloss: 0.145659\n",
      "[54]\ttraining's binary_logloss: 0.139496\tvalid_1's binary_logloss: 0.145474\n",
      "[55]\ttraining's binary_logloss: 0.13926\tvalid_1's binary_logloss: 0.145299\n",
      "[56]\ttraining's binary_logloss: 0.139024\tvalid_1's binary_logloss: 0.145121\n",
      "[57]\ttraining's binary_logloss: 0.138793\tvalid_1's binary_logloss: 0.144948\n",
      "[58]\ttraining's binary_logloss: 0.138567\tvalid_1's binary_logloss: 0.144784\n",
      "[59]\ttraining's binary_logloss: 0.138341\tvalid_1's binary_logloss: 0.144624\n",
      "[60]\ttraining's binary_logloss: 0.138127\tvalid_1's binary_logloss: 0.144461\n",
      "[61]\ttraining's binary_logloss: 0.137911\tvalid_1's binary_logloss: 0.144295\n",
      "[62]\ttraining's binary_logloss: 0.137692\tvalid_1's binary_logloss: 0.144135\n",
      "[63]\ttraining's binary_logloss: 0.137475\tvalid_1's binary_logloss: 0.143972\n",
      "[64]\ttraining's binary_logloss: 0.137268\tvalid_1's binary_logloss: 0.143825\n",
      "[65]\ttraining's binary_logloss: 0.137064\tvalid_1's binary_logloss: 0.143684\n",
      "[66]\ttraining's binary_logloss: 0.136865\tvalid_1's binary_logloss: 0.143538\n",
      "[67]\ttraining's binary_logloss: 0.136671\tvalid_1's binary_logloss: 0.1434\n",
      "[68]\ttraining's binary_logloss: 0.13648\tvalid_1's binary_logloss: 0.143266\n",
      "[69]\ttraining's binary_logloss: 0.136293\tvalid_1's binary_logloss: 0.143128\n",
      "[70]\ttraining's binary_logloss: 0.136095\tvalid_1's binary_logloss: 0.142994\n",
      "[71]\ttraining's binary_logloss: 0.135914\tvalid_1's binary_logloss: 0.142861\n",
      "[72]\ttraining's binary_logloss: 0.135726\tvalid_1's binary_logloss: 0.142725\n",
      "[73]\ttraining's binary_logloss: 0.135543\tvalid_1's binary_logloss: 0.142589\n",
      "[74]\ttraining's binary_logloss: 0.135368\tvalid_1's binary_logloss: 0.142465\n",
      "[75]\ttraining's binary_logloss: 0.135184\tvalid_1's binary_logloss: 0.142345\n",
      "[76]\ttraining's binary_logloss: 0.135008\tvalid_1's binary_logloss: 0.142227\n",
      "[77]\ttraining's binary_logloss: 0.134832\tvalid_1's binary_logloss: 0.142105\n",
      "[78]\ttraining's binary_logloss: 0.134656\tvalid_1's binary_logloss: 0.141985\n",
      "[79]\ttraining's binary_logloss: 0.134484\tvalid_1's binary_logloss: 0.141864\n",
      "[80]\ttraining's binary_logloss: 0.134318\tvalid_1's binary_logloss: 0.14176\n",
      "[81]\ttraining's binary_logloss: 0.134155\tvalid_1's binary_logloss: 0.141647\n",
      "[82]\ttraining's binary_logloss: 0.134001\tvalid_1's binary_logloss: 0.141538\n",
      "[83]\ttraining's binary_logloss: 0.13384\tvalid_1's binary_logloss: 0.141436\n",
      "[84]\ttraining's binary_logloss: 0.133681\tvalid_1's binary_logloss: 0.141339\n",
      "[85]\ttraining's binary_logloss: 0.133523\tvalid_1's binary_logloss: 0.14124\n",
      "[86]\ttraining's binary_logloss: 0.133364\tvalid_1's binary_logloss: 0.141144\n",
      "[87]\ttraining's binary_logloss: 0.133209\tvalid_1's binary_logloss: 0.14105\n",
      "[88]\ttraining's binary_logloss: 0.133058\tvalid_1's binary_logloss: 0.140955\n",
      "[89]\ttraining's binary_logloss: 0.13291\tvalid_1's binary_logloss: 0.140861\n",
      "[90]\ttraining's binary_logloss: 0.132763\tvalid_1's binary_logloss: 0.140776\n",
      "[91]\ttraining's binary_logloss: 0.132619\tvalid_1's binary_logloss: 0.140682\n",
      "[92]\ttraining's binary_logloss: 0.132478\tvalid_1's binary_logloss: 0.140598\n",
      "[93]\ttraining's binary_logloss: 0.132338\tvalid_1's binary_logloss: 0.140503\n",
      "[94]\ttraining's binary_logloss: 0.1322\tvalid_1's binary_logloss: 0.140416\n",
      "[95]\ttraining's binary_logloss: 0.132067\tvalid_1's binary_logloss: 0.140331\n",
      "[96]\ttraining's binary_logloss: 0.131934\tvalid_1's binary_logloss: 0.140247\n",
      "[97]\ttraining's binary_logloss: 0.131805\tvalid_1's binary_logloss: 0.140168\n",
      "[98]\ttraining's binary_logloss: 0.131668\tvalid_1's binary_logloss: 0.140083\n",
      "[99]\ttraining's binary_logloss: 0.131536\tvalid_1's binary_logloss: 0.140004\n",
      "[100]\ttraining's binary_logloss: 0.131406\tvalid_1's binary_logloss: 0.13992\n",
      "[101]\ttraining's binary_logloss: 0.131279\tvalid_1's binary_logloss: 0.139838\n",
      "[102]\ttraining's binary_logloss: 0.131146\tvalid_1's binary_logloss: 0.139751\n",
      "[103]\ttraining's binary_logloss: 0.13101\tvalid_1's binary_logloss: 0.139662\n",
      "[104]\ttraining's binary_logloss: 0.13088\tvalid_1's binary_logloss: 0.139576\n",
      "[105]\ttraining's binary_logloss: 0.130754\tvalid_1's binary_logloss: 0.139495\n",
      "[106]\ttraining's binary_logloss: 0.130624\tvalid_1's binary_logloss: 0.139419\n",
      "[107]\ttraining's binary_logloss: 0.130505\tvalid_1's binary_logloss: 0.139348\n",
      "[108]\ttraining's binary_logloss: 0.13038\tvalid_1's binary_logloss: 0.139263\n",
      "[109]\ttraining's binary_logloss: 0.130261\tvalid_1's binary_logloss: 0.139187\n",
      "[110]\ttraining's binary_logloss: 0.130135\tvalid_1's binary_logloss: 0.139113\n",
      "[111]\ttraining's binary_logloss: 0.130021\tvalid_1's binary_logloss: 0.139032\n",
      "[112]\ttraining's binary_logloss: 0.129906\tvalid_1's binary_logloss: 0.138957\n",
      "[113]\ttraining's binary_logloss: 0.129795\tvalid_1's binary_logloss: 0.138895\n",
      "[114]\ttraining's binary_logloss: 0.129683\tvalid_1's binary_logloss: 0.138828\n",
      "[115]\ttraining's binary_logloss: 0.129566\tvalid_1's binary_logloss: 0.138771\n",
      "[116]\ttraining's binary_logloss: 0.12945\tvalid_1's binary_logloss: 0.138719\n",
      "[117]\ttraining's binary_logloss: 0.129339\tvalid_1's binary_logloss: 0.138658\n",
      "[118]\ttraining's binary_logloss: 0.129225\tvalid_1's binary_logloss: 0.138598\n",
      "[119]\ttraining's binary_logloss: 0.129115\tvalid_1's binary_logloss: 0.138534\n",
      "[120]\ttraining's binary_logloss: 0.128986\tvalid_1's binary_logloss: 0.138479\n",
      "[121]\ttraining's binary_logloss: 0.128876\tvalid_1's binary_logloss: 0.138422\n",
      "[122]\ttraining's binary_logloss: 0.128755\tvalid_1's binary_logloss: 0.13837\n",
      "[123]\ttraining's binary_logloss: 0.128647\tvalid_1's binary_logloss: 0.138315\n",
      "[124]\ttraining's binary_logloss: 0.128537\tvalid_1's binary_logloss: 0.138261\n",
      "[125]\ttraining's binary_logloss: 0.128434\tvalid_1's binary_logloss: 0.138212\n",
      "[126]\ttraining's binary_logloss: 0.128333\tvalid_1's binary_logloss: 0.138164\n",
      "[127]\ttraining's binary_logloss: 0.128222\tvalid_1's binary_logloss: 0.138116\n",
      "[128]\ttraining's binary_logloss: 0.128125\tvalid_1's binary_logloss: 0.138062\n",
      "[129]\ttraining's binary_logloss: 0.128021\tvalid_1's binary_logloss: 0.138015\n",
      "[130]\ttraining's binary_logloss: 0.127926\tvalid_1's binary_logloss: 0.137968\n",
      "[131]\ttraining's binary_logloss: 0.127818\tvalid_1's binary_logloss: 0.137922\n",
      "[132]\ttraining's binary_logloss: 0.127713\tvalid_1's binary_logloss: 0.137879\n",
      "[133]\ttraining's binary_logloss: 0.127613\tvalid_1's binary_logloss: 0.137839\n",
      "[134]\ttraining's binary_logloss: 0.127514\tvalid_1's binary_logloss: 0.137797\n",
      "[135]\ttraining's binary_logloss: 0.127423\tvalid_1's binary_logloss: 0.137751\n",
      "[136]\ttraining's binary_logloss: 0.127325\tvalid_1's binary_logloss: 0.137714\n",
      "[137]\ttraining's binary_logloss: 0.12723\tvalid_1's binary_logloss: 0.137675\n",
      "[138]\ttraining's binary_logloss: 0.127138\tvalid_1's binary_logloss: 0.137638\n",
      "[139]\ttraining's binary_logloss: 0.12705\tvalid_1's binary_logloss: 0.137599\n",
      "[140]\ttraining's binary_logloss: 0.12696\tvalid_1's binary_logloss: 0.137559\n",
      "[141]\ttraining's binary_logloss: 0.12687\tvalid_1's binary_logloss: 0.137514\n",
      "[142]\ttraining's binary_logloss: 0.126786\tvalid_1's binary_logloss: 0.13747\n",
      "[143]\ttraining's binary_logloss: 0.1267\tvalid_1's binary_logloss: 0.137434\n",
      "[144]\ttraining's binary_logloss: 0.126615\tvalid_1's binary_logloss: 0.137394\n",
      "[145]\ttraining's binary_logloss: 0.126535\tvalid_1's binary_logloss: 0.137356\n",
      "[146]\ttraining's binary_logloss: 0.126444\tvalid_1's binary_logloss: 0.137331\n",
      "[147]\ttraining's binary_logloss: 0.126363\tvalid_1's binary_logloss: 0.137302\n",
      "[148]\ttraining's binary_logloss: 0.126282\tvalid_1's binary_logloss: 0.137268\n",
      "[149]\ttraining's binary_logloss: 0.126198\tvalid_1's binary_logloss: 0.137236\n",
      "[150]\ttraining's binary_logloss: 0.126108\tvalid_1's binary_logloss: 0.137207\n",
      "[151]\ttraining's binary_logloss: 0.12602\tvalid_1's binary_logloss: 0.13717\n",
      "[152]\ttraining's binary_logloss: 0.125927\tvalid_1's binary_logloss: 0.137139\n",
      "[153]\ttraining's binary_logloss: 0.125842\tvalid_1's binary_logloss: 0.137107\n",
      "[154]\ttraining's binary_logloss: 0.125763\tvalid_1's binary_logloss: 0.137075\n",
      "[155]\ttraining's binary_logloss: 0.125681\tvalid_1's binary_logloss: 0.137043\n",
      "[156]\ttraining's binary_logloss: 0.125592\tvalid_1's binary_logloss: 0.137014\n",
      "[157]\ttraining's binary_logloss: 0.125499\tvalid_1's binary_logloss: 0.136977\n",
      "[158]\ttraining's binary_logloss: 0.125419\tvalid_1's binary_logloss: 0.136947\n",
      "[159]\ttraining's binary_logloss: 0.12533\tvalid_1's binary_logloss: 0.136909\n",
      "[160]\ttraining's binary_logloss: 0.125246\tvalid_1's binary_logloss: 0.136876\n",
      "[161]\ttraining's binary_logloss: 0.125174\tvalid_1's binary_logloss: 0.13685\n",
      "[162]\ttraining's binary_logloss: 0.12509\tvalid_1's binary_logloss: 0.136822\n",
      "[163]\ttraining's binary_logloss: 0.125011\tvalid_1's binary_logloss: 0.136789\n",
      "[164]\ttraining's binary_logloss: 0.124933\tvalid_1's binary_logloss: 0.136759\n",
      "[165]\ttraining's binary_logloss: 0.12485\tvalid_1's binary_logloss: 0.136723\n",
      "[166]\ttraining's binary_logloss: 0.124775\tvalid_1's binary_logloss: 0.13669\n",
      "[167]\ttraining's binary_logloss: 0.124695\tvalid_1's binary_logloss: 0.136662\n",
      "[168]\ttraining's binary_logloss: 0.124621\tvalid_1's binary_logloss: 0.136627\n",
      "[169]\ttraining's binary_logloss: 0.124555\tvalid_1's binary_logloss: 0.136604\n",
      "[170]\ttraining's binary_logloss: 0.124479\tvalid_1's binary_logloss: 0.136579\n",
      "[171]\ttraining's binary_logloss: 0.124403\tvalid_1's binary_logloss: 0.136548\n",
      "[172]\ttraining's binary_logloss: 0.124333\tvalid_1's binary_logloss: 0.13652\n",
      "[173]\ttraining's binary_logloss: 0.124256\tvalid_1's binary_logloss: 0.136491\n",
      "[174]\ttraining's binary_logloss: 0.124178\tvalid_1's binary_logloss: 0.136466\n",
      "[175]\ttraining's binary_logloss: 0.124107\tvalid_1's binary_logloss: 0.136438\n",
      "[176]\ttraining's binary_logloss: 0.124029\tvalid_1's binary_logloss: 0.136415\n",
      "[177]\ttraining's binary_logloss: 0.123963\tvalid_1's binary_logloss: 0.136393\n",
      "[178]\ttraining's binary_logloss: 0.123896\tvalid_1's binary_logloss: 0.13637\n",
      "[179]\ttraining's binary_logloss: 0.123831\tvalid_1's binary_logloss: 0.136344\n",
      "[180]\ttraining's binary_logloss: 0.123769\tvalid_1's binary_logloss: 0.136323\n",
      "[181]\ttraining's binary_logloss: 0.1237\tvalid_1's binary_logloss: 0.1363\n",
      "[182]\ttraining's binary_logloss: 0.123618\tvalid_1's binary_logloss: 0.136281\n",
      "[183]\ttraining's binary_logloss: 0.123551\tvalid_1's binary_logloss: 0.136261\n",
      "[184]\ttraining's binary_logloss: 0.123472\tvalid_1's binary_logloss: 0.136239\n",
      "[185]\ttraining's binary_logloss: 0.123404\tvalid_1's binary_logloss: 0.136222\n",
      "[186]\ttraining's binary_logloss: 0.123327\tvalid_1's binary_logloss: 0.1362\n",
      "[187]\ttraining's binary_logloss: 0.123254\tvalid_1's binary_logloss: 0.136184\n",
      "[188]\ttraining's binary_logloss: 0.123179\tvalid_1's binary_logloss: 0.136167\n",
      "[189]\ttraining's binary_logloss: 0.123111\tvalid_1's binary_logloss: 0.136147\n",
      "[190]\ttraining's binary_logloss: 0.123043\tvalid_1's binary_logloss: 0.136125\n",
      "[191]\ttraining's binary_logloss: 0.12297\tvalid_1's binary_logloss: 0.136104\n",
      "[192]\ttraining's binary_logloss: 0.1229\tvalid_1's binary_logloss: 0.136086\n",
      "[193]\ttraining's binary_logloss: 0.122833\tvalid_1's binary_logloss: 0.136074\n",
      "[194]\ttraining's binary_logloss: 0.122762\tvalid_1's binary_logloss: 0.136057\n",
      "[195]\ttraining's binary_logloss: 0.122699\tvalid_1's binary_logloss: 0.136042\n",
      "[196]\ttraining's binary_logloss: 0.122626\tvalid_1's binary_logloss: 0.136025\n",
      "[197]\ttraining's binary_logloss: 0.122565\tvalid_1's binary_logloss: 0.136005\n",
      "[198]\ttraining's binary_logloss: 0.122501\tvalid_1's binary_logloss: 0.135987\n",
      "[199]\ttraining's binary_logloss: 0.122437\tvalid_1's binary_logloss: 0.135967\n",
      "[200]\ttraining's binary_logloss: 0.12237\tvalid_1's binary_logloss: 0.13595\n",
      "[201]\ttraining's binary_logloss: 0.122302\tvalid_1's binary_logloss: 0.135936\n",
      "[202]\ttraining's binary_logloss: 0.122235\tvalid_1's binary_logloss: 0.135922\n",
      "[203]\ttraining's binary_logloss: 0.122175\tvalid_1's binary_logloss: 0.135908\n",
      "[204]\ttraining's binary_logloss: 0.122114\tvalid_1's binary_logloss: 0.135892\n",
      "[205]\ttraining's binary_logloss: 0.122053\tvalid_1's binary_logloss: 0.135874\n",
      "[206]\ttraining's binary_logloss: 0.121989\tvalid_1's binary_logloss: 0.135856\n",
      "[207]\ttraining's binary_logloss: 0.121927\tvalid_1's binary_logloss: 0.135842\n",
      "[208]\ttraining's binary_logloss: 0.121868\tvalid_1's binary_logloss: 0.135826\n",
      "[209]\ttraining's binary_logloss: 0.121802\tvalid_1's binary_logloss: 0.135816\n",
      "[210]\ttraining's binary_logloss: 0.121748\tvalid_1's binary_logloss: 0.135794\n",
      "[211]\ttraining's binary_logloss: 0.121685\tvalid_1's binary_logloss: 0.135781\n",
      "[212]\ttraining's binary_logloss: 0.12162\tvalid_1's binary_logloss: 0.135764\n",
      "[213]\ttraining's binary_logloss: 0.121557\tvalid_1's binary_logloss: 0.135756\n",
      "[214]\ttraining's binary_logloss: 0.121489\tvalid_1's binary_logloss: 0.135742\n",
      "[215]\ttraining's binary_logloss: 0.121426\tvalid_1's binary_logloss: 0.135732\n",
      "[216]\ttraining's binary_logloss: 0.12136\tvalid_1's binary_logloss: 0.135717\n",
      "[217]\ttraining's binary_logloss: 0.1213\tvalid_1's binary_logloss: 0.135697\n",
      "[218]\ttraining's binary_logloss: 0.121247\tvalid_1's binary_logloss: 0.135675\n",
      "[219]\ttraining's binary_logloss: 0.121189\tvalid_1's binary_logloss: 0.135661\n",
      "[220]\ttraining's binary_logloss: 0.121129\tvalid_1's binary_logloss: 0.135653\n",
      "[221]\ttraining's binary_logloss: 0.12107\tvalid_1's binary_logloss: 0.135632\n",
      "[222]\ttraining's binary_logloss: 0.121\tvalid_1's binary_logloss: 0.135614\n",
      "[223]\ttraining's binary_logloss: 0.120943\tvalid_1's binary_logloss: 0.135606\n",
      "[224]\ttraining's binary_logloss: 0.120877\tvalid_1's binary_logloss: 0.135589\n",
      "[225]\ttraining's binary_logloss: 0.120815\tvalid_1's binary_logloss: 0.135571\n",
      "[226]\ttraining's binary_logloss: 0.120754\tvalid_1's binary_logloss: 0.135564\n",
      "[227]\ttraining's binary_logloss: 0.120695\tvalid_1's binary_logloss: 0.135558\n",
      "[228]\ttraining's binary_logloss: 0.120639\tvalid_1's binary_logloss: 0.135552\n",
      "[229]\ttraining's binary_logloss: 0.120581\tvalid_1's binary_logloss: 0.135534\n",
      "[230]\ttraining's binary_logloss: 0.120529\tvalid_1's binary_logloss: 0.135524\n",
      "[231]\ttraining's binary_logloss: 0.120479\tvalid_1's binary_logloss: 0.135508\n",
      "[232]\ttraining's binary_logloss: 0.120427\tvalid_1's binary_logloss: 0.135498\n",
      "[233]\ttraining's binary_logloss: 0.120373\tvalid_1's binary_logloss: 0.135493\n",
      "[234]\ttraining's binary_logloss: 0.120322\tvalid_1's binary_logloss: 0.135482\n",
      "[235]\ttraining's binary_logloss: 0.120261\tvalid_1's binary_logloss: 0.135467\n",
      "[236]\ttraining's binary_logloss: 0.120207\tvalid_1's binary_logloss: 0.135448\n",
      "[237]\ttraining's binary_logloss: 0.120157\tvalid_1's binary_logloss: 0.135438\n",
      "[238]\ttraining's binary_logloss: 0.120103\tvalid_1's binary_logloss: 0.135431\n",
      "[239]\ttraining's binary_logloss: 0.120057\tvalid_1's binary_logloss: 0.135425\n",
      "[240]\ttraining's binary_logloss: 0.12001\tvalid_1's binary_logloss: 0.135409\n",
      "[241]\ttraining's binary_logloss: 0.119959\tvalid_1's binary_logloss: 0.135402\n",
      "[242]\ttraining's binary_logloss: 0.11991\tvalid_1's binary_logloss: 0.135392\n",
      "[243]\ttraining's binary_logloss: 0.11986\tvalid_1's binary_logloss: 0.135381\n",
      "[244]\ttraining's binary_logloss: 0.119793\tvalid_1's binary_logloss: 0.135366\n",
      "[245]\ttraining's binary_logloss: 0.119745\tvalid_1's binary_logloss: 0.135357\n",
      "[246]\ttraining's binary_logloss: 0.119695\tvalid_1's binary_logloss: 0.135354\n",
      "[247]\ttraining's binary_logloss: 0.119645\tvalid_1's binary_logloss: 0.135341\n",
      "[248]\ttraining's binary_logloss: 0.119597\tvalid_1's binary_logloss: 0.135333\n",
      "[249]\ttraining's binary_logloss: 0.119547\tvalid_1's binary_logloss: 0.135323\n",
      "[250]\ttraining's binary_logloss: 0.1195\tvalid_1's binary_logloss: 0.135321\n",
      "[251]\ttraining's binary_logloss: 0.119451\tvalid_1's binary_logloss: 0.135304\n",
      "[252]\ttraining's binary_logloss: 0.119405\tvalid_1's binary_logloss: 0.135301\n",
      "[253]\ttraining's binary_logloss: 0.119361\tvalid_1's binary_logloss: 0.135291\n",
      "[254]\ttraining's binary_logloss: 0.119316\tvalid_1's binary_logloss: 0.135285\n",
      "[255]\ttraining's binary_logloss: 0.119261\tvalid_1's binary_logloss: 0.135276\n",
      "[256]\ttraining's binary_logloss: 0.11921\tvalid_1's binary_logloss: 0.135277\n",
      "[257]\ttraining's binary_logloss: 0.119159\tvalid_1's binary_logloss: 0.135275\n",
      "[258]\ttraining's binary_logloss: 0.119109\tvalid_1's binary_logloss: 0.135258\n",
      "[259]\ttraining's binary_logloss: 0.11906\tvalid_1's binary_logloss: 0.13526\n",
      "[260]\ttraining's binary_logloss: 0.119014\tvalid_1's binary_logloss: 0.135252\n",
      "[261]\ttraining's binary_logloss: 0.118969\tvalid_1's binary_logloss: 0.135246\n",
      "[262]\ttraining's binary_logloss: 0.118923\tvalid_1's binary_logloss: 0.135248\n",
      "[263]\ttraining's binary_logloss: 0.118866\tvalid_1's binary_logloss: 0.135249\n",
      "[264]\ttraining's binary_logloss: 0.118822\tvalid_1's binary_logloss: 0.135233\n",
      "[265]\ttraining's binary_logloss: 0.11878\tvalid_1's binary_logloss: 0.135225\n",
      "[266]\ttraining's binary_logloss: 0.118726\tvalid_1's binary_logloss: 0.135214\n",
      "[267]\ttraining's binary_logloss: 0.118682\tvalid_1's binary_logloss: 0.135211\n",
      "[268]\ttraining's binary_logloss: 0.118629\tvalid_1's binary_logloss: 0.13521\n",
      "[269]\ttraining's binary_logloss: 0.118577\tvalid_1's binary_logloss: 0.135205\n",
      "[270]\ttraining's binary_logloss: 0.118526\tvalid_1's binary_logloss: 0.1352\n",
      "[271]\ttraining's binary_logloss: 0.118473\tvalid_1's binary_logloss: 0.135196\n",
      "[272]\ttraining's binary_logloss: 0.118425\tvalid_1's binary_logloss: 0.135196\n",
      "[273]\ttraining's binary_logloss: 0.118375\tvalid_1's binary_logloss: 0.135192\n",
      "[274]\ttraining's binary_logloss: 0.118328\tvalid_1's binary_logloss: 0.135182\n",
      "[275]\ttraining's binary_logloss: 0.118285\tvalid_1's binary_logloss: 0.135172\n",
      "[276]\ttraining's binary_logloss: 0.118239\tvalid_1's binary_logloss: 0.135173\n",
      "[277]\ttraining's binary_logloss: 0.118187\tvalid_1's binary_logloss: 0.135169\n",
      "[278]\ttraining's binary_logloss: 0.118145\tvalid_1's binary_logloss: 0.135164\n",
      "[279]\ttraining's binary_logloss: 0.118101\tvalid_1's binary_logloss: 0.13516\n",
      "[280]\ttraining's binary_logloss: 0.118059\tvalid_1's binary_logloss: 0.135151\n",
      "[281]\ttraining's binary_logloss: 0.118011\tvalid_1's binary_logloss: 0.135144\n",
      "[282]\ttraining's binary_logloss: 0.117968\tvalid_1's binary_logloss: 0.135142\n",
      "[283]\ttraining's binary_logloss: 0.117921\tvalid_1's binary_logloss: 0.135133\n",
      "[284]\ttraining's binary_logloss: 0.117871\tvalid_1's binary_logloss: 0.135129\n",
      "[285]\ttraining's binary_logloss: 0.117826\tvalid_1's binary_logloss: 0.135124\n",
      "[286]\ttraining's binary_logloss: 0.11778\tvalid_1's binary_logloss: 0.13512\n",
      "[287]\ttraining's binary_logloss: 0.117735\tvalid_1's binary_logloss: 0.135121\n",
      "[288]\ttraining's binary_logloss: 0.117687\tvalid_1's binary_logloss: 0.135108\n",
      "[289]\ttraining's binary_logloss: 0.117646\tvalid_1's binary_logloss: 0.1351\n",
      "[290]\ttraining's binary_logloss: 0.117597\tvalid_1's binary_logloss: 0.135104\n",
      "[291]\ttraining's binary_logloss: 0.117552\tvalid_1's binary_logloss: 0.135087\n",
      "[292]\ttraining's binary_logloss: 0.117511\tvalid_1's binary_logloss: 0.13508\n",
      "[293]\ttraining's binary_logloss: 0.117464\tvalid_1's binary_logloss: 0.135075\n",
      "[294]\ttraining's binary_logloss: 0.117422\tvalid_1's binary_logloss: 0.13506\n",
      "[295]\ttraining's binary_logloss: 0.117378\tvalid_1's binary_logloss: 0.135056\n",
      "[296]\ttraining's binary_logloss: 0.117342\tvalid_1's binary_logloss: 0.135052\n",
      "[297]\ttraining's binary_logloss: 0.1173\tvalid_1's binary_logloss: 0.135048\n",
      "[298]\ttraining's binary_logloss: 0.11726\tvalid_1's binary_logloss: 0.135041\n",
      "[299]\ttraining's binary_logloss: 0.117217\tvalid_1's binary_logloss: 0.13504\n",
      "[300]\ttraining's binary_logloss: 0.117179\tvalid_1's binary_logloss: 0.135037\n",
      "[301]\ttraining's binary_logloss: 0.11714\tvalid_1's binary_logloss: 0.135029\n",
      "[302]\ttraining's binary_logloss: 0.117101\tvalid_1's binary_logloss: 0.135029\n",
      "[303]\ttraining's binary_logloss: 0.11706\tvalid_1's binary_logloss: 0.135026\n",
      "[304]\ttraining's binary_logloss: 0.117015\tvalid_1's binary_logloss: 0.13503\n",
      "[305]\ttraining's binary_logloss: 0.116978\tvalid_1's binary_logloss: 0.135025\n",
      "[306]\ttraining's binary_logloss: 0.116941\tvalid_1's binary_logloss: 0.13502\n",
      "[307]\ttraining's binary_logloss: 0.116898\tvalid_1's binary_logloss: 0.135017\n",
      "[308]\ttraining's binary_logloss: 0.116857\tvalid_1's binary_logloss: 0.135017\n",
      "[309]\ttraining's binary_logloss: 0.116816\tvalid_1's binary_logloss: 0.135016\n",
      "[310]\ttraining's binary_logloss: 0.116775\tvalid_1's binary_logloss: 0.135012\n",
      "[311]\ttraining's binary_logloss: 0.116738\tvalid_1's binary_logloss: 0.13501\n",
      "[312]\ttraining's binary_logloss: 0.116693\tvalid_1's binary_logloss: 0.135018\n",
      "[313]\ttraining's binary_logloss: 0.116654\tvalid_1's binary_logloss: 0.13502\n",
      "[314]\ttraining's binary_logloss: 0.116619\tvalid_1's binary_logloss: 0.135015\n",
      "[315]\ttraining's binary_logloss: 0.116576\tvalid_1's binary_logloss: 0.13501\n",
      "[316]\ttraining's binary_logloss: 0.116528\tvalid_1's binary_logloss: 0.13501\n",
      "[317]\ttraining's binary_logloss: 0.116491\tvalid_1's binary_logloss: 0.135007\n",
      "[318]\ttraining's binary_logloss: 0.116457\tvalid_1's binary_logloss: 0.135004\n",
      "[319]\ttraining's binary_logloss: 0.116411\tvalid_1's binary_logloss: 0.135003\n",
      "[320]\ttraining's binary_logloss: 0.116377\tvalid_1's binary_logloss: 0.135001\n",
      "[321]\ttraining's binary_logloss: 0.116334\tvalid_1's binary_logloss: 0.135\n",
      "[322]\ttraining's binary_logloss: 0.116298\tvalid_1's binary_logloss: 0.134996\n",
      "[323]\ttraining's binary_logloss: 0.116261\tvalid_1's binary_logloss: 0.134998\n",
      "[324]\ttraining's binary_logloss: 0.116225\tvalid_1's binary_logloss: 0.134997\n",
      "[325]\ttraining's binary_logloss: 0.11619\tvalid_1's binary_logloss: 0.134996\n",
      "[326]\ttraining's binary_logloss: 0.116129\tvalid_1's binary_logloss: 0.134995\n",
      "[327]\ttraining's binary_logloss: 0.116096\tvalid_1's binary_logloss: 0.134996\n",
      "[328]\ttraining's binary_logloss: 0.116046\tvalid_1's binary_logloss: 0.134992\n",
      "[329]\ttraining's binary_logloss: 0.116014\tvalid_1's binary_logloss: 0.134993\n",
      "[330]\ttraining's binary_logloss: 0.115965\tvalid_1's binary_logloss: 0.134992\n",
      "[331]\ttraining's binary_logloss: 0.11593\tvalid_1's binary_logloss: 0.134993\n",
      "[332]\ttraining's binary_logloss: 0.115892\tvalid_1's binary_logloss: 0.134996\n",
      "[333]\ttraining's binary_logloss: 0.115851\tvalid_1's binary_logloss: 0.135004\n",
      "[334]\ttraining's binary_logloss: 0.115797\tvalid_1's binary_logloss: 0.134999\n",
      "[335]\ttraining's binary_logloss: 0.115768\tvalid_1's binary_logloss: 0.134995\n",
      "[336]\ttraining's binary_logloss: 0.115737\tvalid_1's binary_logloss: 0.134995\n",
      "[337]\ttraining's binary_logloss: 0.115689\tvalid_1's binary_logloss: 0.134991\n",
      "[338]\ttraining's binary_logloss: 0.11565\tvalid_1's binary_logloss: 0.134998\n",
      "[339]\ttraining's binary_logloss: 0.115602\tvalid_1's binary_logloss: 0.135\n",
      "[340]\ttraining's binary_logloss: 0.115572\tvalid_1's binary_logloss: 0.134998\n",
      "[341]\ttraining's binary_logloss: 0.115526\tvalid_1's binary_logloss: 0.135002\n",
      "[342]\ttraining's binary_logloss: 0.115494\tvalid_1's binary_logloss: 0.134994\n",
      "[343]\ttraining's binary_logloss: 0.115453\tvalid_1's binary_logloss: 0.134995\n",
      "[344]\ttraining's binary_logloss: 0.115415\tvalid_1's binary_logloss: 0.135003\n",
      "[345]\ttraining's binary_logloss: 0.115369\tvalid_1's binary_logloss: 0.135002\n",
      "[346]\ttraining's binary_logloss: 0.115344\tvalid_1's binary_logloss: 0.134999\n",
      "[347]\ttraining's binary_logloss: 0.115304\tvalid_1's binary_logloss: 0.135001\n",
      "[348]\ttraining's binary_logloss: 0.115267\tvalid_1's binary_logloss: 0.135\n",
      "[349]\ttraining's binary_logloss: 0.115223\tvalid_1's binary_logloss: 0.135003\n",
      "[350]\ttraining's binary_logloss: 0.115177\tvalid_1's binary_logloss: 0.134998\n",
      "[351]\ttraining's binary_logloss: 0.115146\tvalid_1's binary_logloss: 0.134988\n",
      "[352]\ttraining's binary_logloss: 0.115106\tvalid_1's binary_logloss: 0.134989\n",
      "[353]\ttraining's binary_logloss: 0.115067\tvalid_1's binary_logloss: 0.13499\n",
      "[354]\ttraining's binary_logloss: 0.115035\tvalid_1's binary_logloss: 0.134986\n",
      "[355]\ttraining's binary_logloss: 0.114993\tvalid_1's binary_logloss: 0.134983\n",
      "[356]\ttraining's binary_logloss: 0.114967\tvalid_1's binary_logloss: 0.134976\n",
      "[357]\ttraining's binary_logloss: 0.114925\tvalid_1's binary_logloss: 0.134971\n",
      "[358]\ttraining's binary_logloss: 0.114885\tvalid_1's binary_logloss: 0.134967\n",
      "[359]\ttraining's binary_logloss: 0.114851\tvalid_1's binary_logloss: 0.134966\n",
      "[360]\ttraining's binary_logloss: 0.114816\tvalid_1's binary_logloss: 0.134968\n",
      "[361]\ttraining's binary_logloss: 0.114786\tvalid_1's binary_logloss: 0.134963\n",
      "[362]\ttraining's binary_logloss: 0.114743\tvalid_1's binary_logloss: 0.134956\n",
      "[363]\ttraining's binary_logloss: 0.114707\tvalid_1's binary_logloss: 0.134959\n",
      "[364]\ttraining's binary_logloss: 0.114665\tvalid_1's binary_logloss: 0.134955\n",
      "[365]\ttraining's binary_logloss: 0.11463\tvalid_1's binary_logloss: 0.134955\n",
      "[366]\ttraining's binary_logloss: 0.114595\tvalid_1's binary_logloss: 0.134958\n",
      "[367]\ttraining's binary_logloss: 0.114559\tvalid_1's binary_logloss: 0.134958\n",
      "[368]\ttraining's binary_logloss: 0.114522\tvalid_1's binary_logloss: 0.134955\n",
      "[369]\ttraining's binary_logloss: 0.114489\tvalid_1's binary_logloss: 0.134959\n",
      "[370]\ttraining's binary_logloss: 0.114449\tvalid_1's binary_logloss: 0.134958\n",
      "[371]\ttraining's binary_logloss: 0.114422\tvalid_1's binary_logloss: 0.134957\n",
      "[372]\ttraining's binary_logloss: 0.114385\tvalid_1's binary_logloss: 0.134958\n",
      "[373]\ttraining's binary_logloss: 0.114347\tvalid_1's binary_logloss: 0.134954\n",
      "[374]\ttraining's binary_logloss: 0.114312\tvalid_1's binary_logloss: 0.134952\n",
      "[375]\ttraining's binary_logloss: 0.114279\tvalid_1's binary_logloss: 0.134956\n",
      "[376]\ttraining's binary_logloss: 0.114242\tvalid_1's binary_logloss: 0.134955\n",
      "[377]\ttraining's binary_logloss: 0.114215\tvalid_1's binary_logloss: 0.134952\n",
      "[378]\ttraining's binary_logloss: 0.114181\tvalid_1's binary_logloss: 0.134955\n",
      "[379]\ttraining's binary_logloss: 0.114149\tvalid_1's binary_logloss: 0.134957\n",
      "[380]\ttraining's binary_logloss: 0.114119\tvalid_1's binary_logloss: 0.134956\n",
      "[381]\ttraining's binary_logloss: 0.114079\tvalid_1's binary_logloss: 0.134957\n",
      "[382]\ttraining's binary_logloss: 0.114056\tvalid_1's binary_logloss: 0.134957\n",
      "[383]\ttraining's binary_logloss: 0.114015\tvalid_1's binary_logloss: 0.134964\n",
      "[384]\ttraining's binary_logloss: 0.113972\tvalid_1's binary_logloss: 0.13496\n",
      "[385]\ttraining's binary_logloss: 0.113941\tvalid_1's binary_logloss: 0.134955\n",
      "[386]\ttraining's binary_logloss: 0.113905\tvalid_1's binary_logloss: 0.134951\n",
      "[387]\ttraining's binary_logloss: 0.113876\tvalid_1's binary_logloss: 0.134948\n",
      "[388]\ttraining's binary_logloss: 0.113845\tvalid_1's binary_logloss: 0.13495\n",
      "[389]\ttraining's binary_logloss: 0.113814\tvalid_1's binary_logloss: 0.134956\n",
      "[390]\ttraining's binary_logloss: 0.113777\tvalid_1's binary_logloss: 0.134956\n",
      "[391]\ttraining's binary_logloss: 0.113744\tvalid_1's binary_logloss: 0.134954\n",
      "[392]\ttraining's binary_logloss: 0.113714\tvalid_1's binary_logloss: 0.134953\n",
      "[393]\ttraining's binary_logloss: 0.113688\tvalid_1's binary_logloss: 0.134953\n",
      "[394]\ttraining's binary_logloss: 0.113652\tvalid_1's binary_logloss: 0.134946\n",
      "[395]\ttraining's binary_logloss: 0.113613\tvalid_1's binary_logloss: 0.134947\n",
      "[396]\ttraining's binary_logloss: 0.113575\tvalid_1's binary_logloss: 0.134955\n",
      "[397]\ttraining's binary_logloss: 0.113541\tvalid_1's binary_logloss: 0.134951\n",
      "[398]\ttraining's binary_logloss: 0.113503\tvalid_1's binary_logloss: 0.13495\n",
      "[399]\ttraining's binary_logloss: 0.113466\tvalid_1's binary_logloss: 0.134954\n",
      "[400]\ttraining's binary_logloss: 0.113435\tvalid_1's binary_logloss: 0.13495\n",
      "[401]\ttraining's binary_logloss: 0.113409\tvalid_1's binary_logloss: 0.134948\n",
      "[402]\ttraining's binary_logloss: 0.113372\tvalid_1's binary_logloss: 0.134942\n",
      "[403]\ttraining's binary_logloss: 0.113335\tvalid_1's binary_logloss: 0.13494\n",
      "[404]\ttraining's binary_logloss: 0.113298\tvalid_1's binary_logloss: 0.134945\n",
      "[405]\ttraining's binary_logloss: 0.113271\tvalid_1's binary_logloss: 0.134939\n",
      "[406]\ttraining's binary_logloss: 0.11324\tvalid_1's binary_logloss: 0.134937\n",
      "[407]\ttraining's binary_logloss: 0.113206\tvalid_1's binary_logloss: 0.13494\n",
      "[408]\ttraining's binary_logloss: 0.113169\tvalid_1's binary_logloss: 0.134942\n",
      "[409]\ttraining's binary_logloss: 0.113138\tvalid_1's binary_logloss: 0.134943\n",
      "[410]\ttraining's binary_logloss: 0.113113\tvalid_1's binary_logloss: 0.134941\n",
      "[411]\ttraining's binary_logloss: 0.113081\tvalid_1's binary_logloss: 0.134941\n",
      "[412]\ttraining's binary_logloss: 0.113057\tvalid_1's binary_logloss: 0.134942\n",
      "[413]\ttraining's binary_logloss: 0.113023\tvalid_1's binary_logloss: 0.134936\n",
      "[414]\ttraining's binary_logloss: 0.112991\tvalid_1's binary_logloss: 0.134939\n",
      "[415]\ttraining's binary_logloss: 0.112965\tvalid_1's binary_logloss: 0.134936\n",
      "[416]\ttraining's binary_logloss: 0.112927\tvalid_1's binary_logloss: 0.134948\n",
      "[417]\ttraining's binary_logloss: 0.112895\tvalid_1's binary_logloss: 0.134939\n",
      "[418]\ttraining's binary_logloss: 0.112869\tvalid_1's binary_logloss: 0.134937\n",
      "[419]\ttraining's binary_logloss: 0.112841\tvalid_1's binary_logloss: 0.134931\n",
      "[420]\ttraining's binary_logloss: 0.112807\tvalid_1's binary_logloss: 0.134926\n",
      "[421]\ttraining's binary_logloss: 0.112784\tvalid_1's binary_logloss: 0.134928\n",
      "[422]\ttraining's binary_logloss: 0.112753\tvalid_1's binary_logloss: 0.13492\n",
      "[423]\ttraining's binary_logloss: 0.112725\tvalid_1's binary_logloss: 0.134924\n",
      "[424]\ttraining's binary_logloss: 0.112692\tvalid_1's binary_logloss: 0.134926\n",
      "[425]\ttraining's binary_logloss: 0.112657\tvalid_1's binary_logloss: 0.134933\n",
      "[426]\ttraining's binary_logloss: 0.112628\tvalid_1's binary_logloss: 0.134932\n",
      "[427]\ttraining's binary_logloss: 0.11259\tvalid_1's binary_logloss: 0.134935\n",
      "[428]\ttraining's binary_logloss: 0.112561\tvalid_1's binary_logloss: 0.134935\n",
      "[429]\ttraining's binary_logloss: 0.112528\tvalid_1's binary_logloss: 0.134934\n",
      "[430]\ttraining's binary_logloss: 0.112496\tvalid_1's binary_logloss: 0.134938\n",
      "[431]\ttraining's binary_logloss: 0.112465\tvalid_1's binary_logloss: 0.134934\n",
      "[432]\ttraining's binary_logloss: 0.112437\tvalid_1's binary_logloss: 0.134933\n",
      "[433]\ttraining's binary_logloss: 0.112405\tvalid_1's binary_logloss: 0.134929\n",
      "[434]\ttraining's binary_logloss: 0.11238\tvalid_1's binary_logloss: 0.134935\n",
      "[435]\ttraining's binary_logloss: 0.112351\tvalid_1's binary_logloss: 0.134937\n",
      "[436]\ttraining's binary_logloss: 0.112325\tvalid_1's binary_logloss: 0.134938\n",
      "[437]\ttraining's binary_logloss: 0.112288\tvalid_1's binary_logloss: 0.134939\n",
      "[438]\ttraining's binary_logloss: 0.112259\tvalid_1's binary_logloss: 0.134944\n",
      "[439]\ttraining's binary_logloss: 0.112227\tvalid_1's binary_logloss: 0.134944\n",
      "[440]\ttraining's binary_logloss: 0.1122\tvalid_1's binary_logloss: 0.134947\n",
      "[441]\ttraining's binary_logloss: 0.112167\tvalid_1's binary_logloss: 0.134946\n",
      "[442]\ttraining's binary_logloss: 0.112137\tvalid_1's binary_logloss: 0.134949\n",
      "[443]\ttraining's binary_logloss: 0.112115\tvalid_1's binary_logloss: 0.134952\n",
      "[444]\ttraining's binary_logloss: 0.112094\tvalid_1's binary_logloss: 0.134957\n",
      "[445]\ttraining's binary_logloss: 0.112061\tvalid_1's binary_logloss: 0.134958\n",
      "[446]\ttraining's binary_logloss: 0.112034\tvalid_1's binary_logloss: 0.134953\n",
      "[447]\ttraining's binary_logloss: 0.112\tvalid_1's binary_logloss: 0.134955\n",
      "[448]\ttraining's binary_logloss: 0.111967\tvalid_1's binary_logloss: 0.134955\n",
      "[449]\ttraining's binary_logloss: 0.111939\tvalid_1's binary_logloss: 0.134963\n",
      "[450]\ttraining's binary_logloss: 0.111914\tvalid_1's binary_logloss: 0.134959\n",
      "[451]\ttraining's binary_logloss: 0.111885\tvalid_1's binary_logloss: 0.134957\n",
      "[452]\ttraining's binary_logloss: 0.111862\tvalid_1's binary_logloss: 0.134955\n",
      "[453]\ttraining's binary_logloss: 0.111836\tvalid_1's binary_logloss: 0.134952\n",
      "[454]\ttraining's binary_logloss: 0.111808\tvalid_1's binary_logloss: 0.13495\n",
      "[455]\ttraining's binary_logloss: 0.111784\tvalid_1's binary_logloss: 0.134952\n",
      "[456]\ttraining's binary_logloss: 0.111756\tvalid_1's binary_logloss: 0.134944\n",
      "[457]\ttraining's binary_logloss: 0.11172\tvalid_1's binary_logloss: 0.134948\n",
      "[458]\ttraining's binary_logloss: 0.111699\tvalid_1's binary_logloss: 0.134949\n",
      "[459]\ttraining's binary_logloss: 0.111679\tvalid_1's binary_logloss: 0.134954\n",
      "[460]\ttraining's binary_logloss: 0.111653\tvalid_1's binary_logloss: 0.134952\n",
      "[461]\ttraining's binary_logloss: 0.111619\tvalid_1's binary_logloss: 0.134958\n",
      "[462]\ttraining's binary_logloss: 0.111583\tvalid_1's binary_logloss: 0.134958\n",
      "[463]\ttraining's binary_logloss: 0.111558\tvalid_1's binary_logloss: 0.134953\n",
      "[464]\ttraining's binary_logloss: 0.111528\tvalid_1's binary_logloss: 0.134953\n",
      "[465]\ttraining's binary_logloss: 0.111503\tvalid_1's binary_logloss: 0.134953\n",
      "[466]\ttraining's binary_logloss: 0.111481\tvalid_1's binary_logloss: 0.134956\n",
      "[467]\ttraining's binary_logloss: 0.111456\tvalid_1's binary_logloss: 0.134956\n",
      "[468]\ttraining's binary_logloss: 0.111422\tvalid_1's binary_logloss: 0.134956\n",
      "[469]\ttraining's binary_logloss: 0.111393\tvalid_1's binary_logloss: 0.134952\n",
      "[470]\ttraining's binary_logloss: 0.11137\tvalid_1's binary_logloss: 0.134949\n",
      "[471]\ttraining's binary_logloss: 0.111348\tvalid_1's binary_logloss: 0.134946\n",
      "[472]\ttraining's binary_logloss: 0.111315\tvalid_1's binary_logloss: 0.134949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8403883460461733"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LGBM 추가\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators= 500\n",
    "                            , learning_rate = 0.01)\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr\n",
    "                 , early_stopping_rounds=50\n",
    "                 , eval_metric = 'logloss'\n",
    "                 , eval_set = evals\n",
    "                 , verbose = True\n",
    "                 )\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric   \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric   \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric   \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric   \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric   \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                              \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric                               \n",
      "100%|██████████| 50/50 [03:51<00:00,  4.63s/trial, best loss: -0.9610299920651965]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6927676666640397,\n",
       " 'learning_rate': 0.019374568079732202,\n",
       " 'max_depth': 19.0,\n",
       " 'n_estimators': 110.0,\n",
       " 'subsample': 0.605538798755866}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LGBM 추가\n",
    "from hyperopt import hp\n",
    "\n",
    "search_space = {\n",
    "    'n_estimators' : scope.int(hp.quniform('n_estimators', 50, 300, 10))\n",
    "    , 'max_depth' : scope.int(hp.quniform('max_depth', 5, 20, 1))\n",
    "    , 'learning_rate' : hp.uniform('learning_rate', 0.01, 0.3)\n",
    "    , 'subsample' : hp.uniform('subsample', 0.5, 1.0)\n",
    "    , 'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "\n",
    "}\n",
    "\n",
    "def objective_func_lgbm(params):\n",
    "    model = LGBMClassifier(\n",
    "        n_estimators = params['n_estimators']\n",
    "        , max_depth = params['max_depth']\n",
    "        , learning_rate = params['learning_rate']\n",
    "        , subsample = params['subsample']\n",
    "        , colsample_bytree = params['colsample_bytree']\n",
    "        , random_state = 42\n",
    "        , eval_metric = 'logloss'\n",
    "    )\n",
    "\n",
    "    score_mean = cross_val_score(model\n",
    "                                , X_train\n",
    "                                , y_train\n",
    "                                , cv = 5\n",
    "                                , scoring = 'accuracy'\n",
    "                                ).mean()\n",
    "    \n",
    "    return {'loss' : -1 * score_mean, 'status' : STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_params_lgbm = fmin(\n",
    "    fn = objective_func_lgbm\n",
    "    , space = search_space\n",
    "    , algo = tpe.suggest\n",
    "    , max_evals = 50\n",
    "    , trials = trials\n",
    ")\n",
    "\n",
    "best_params_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lgbm['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.162676\tvalid_1's binary_logloss: 0.163935\n",
      "[2]\ttraining's binary_logloss: 0.160927\tvalid_1's binary_logloss: 0.162528\n",
      "[3]\ttraining's binary_logloss: 0.159364\tvalid_1's binary_logloss: 0.161205\n",
      "[4]\ttraining's binary_logloss: 0.157936\tvalid_1's binary_logloss: 0.160011\n",
      "[5]\ttraining's binary_logloss: 0.156594\tvalid_1's binary_logloss: 0.158921\n",
      "[6]\ttraining's binary_logloss: 0.155326\tvalid_1's binary_logloss: 0.157887\n",
      "[7]\ttraining's binary_logloss: 0.154159\tvalid_1's binary_logloss: 0.15695\n",
      "[8]\ttraining's binary_logloss: 0.153066\tvalid_1's binary_logloss: 0.156044\n",
      "[9]\ttraining's binary_logloss: 0.152032\tvalid_1's binary_logloss: 0.155224\n",
      "[10]\ttraining's binary_logloss: 0.151064\tvalid_1's binary_logloss: 0.154467\n",
      "[11]\ttraining's binary_logloss: 0.150139\tvalid_1's binary_logloss: 0.153728\n",
      "[12]\ttraining's binary_logloss: 0.149252\tvalid_1's binary_logloss: 0.153007\n",
      "[13]\ttraining's binary_logloss: 0.148426\tvalid_1's binary_logloss: 0.152346\n",
      "[14]\ttraining's binary_logloss: 0.147611\tvalid_1's binary_logloss: 0.151723\n",
      "[15]\ttraining's binary_logloss: 0.14685\tvalid_1's binary_logloss: 0.151127\n",
      "[16]\ttraining's binary_logloss: 0.146125\tvalid_1's binary_logloss: 0.150559\n",
      "[17]\ttraining's binary_logloss: 0.14543\tvalid_1's binary_logloss: 0.150029\n",
      "[18]\ttraining's binary_logloss: 0.144752\tvalid_1's binary_logloss: 0.149513\n",
      "[19]\ttraining's binary_logloss: 0.144109\tvalid_1's binary_logloss: 0.149013\n",
      "[20]\ttraining's binary_logloss: 0.14351\tvalid_1's binary_logloss: 0.148544\n",
      "[21]\ttraining's binary_logloss: 0.142926\tvalid_1's binary_logloss: 0.148076\n",
      "[22]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.147604\n",
      "[23]\ttraining's binary_logloss: 0.1418\tvalid_1's binary_logloss: 0.147191\n",
      "[24]\ttraining's binary_logloss: 0.14126\tvalid_1's binary_logloss: 0.14679\n",
      "[25]\ttraining's binary_logloss: 0.140742\tvalid_1's binary_logloss: 0.14641\n",
      "[26]\ttraining's binary_logloss: 0.140245\tvalid_1's binary_logloss: 0.146035\n",
      "[27]\ttraining's binary_logloss: 0.139747\tvalid_1's binary_logloss: 0.145654\n",
      "[28]\ttraining's binary_logloss: 0.139273\tvalid_1's binary_logloss: 0.145301\n",
      "[29]\ttraining's binary_logloss: 0.138822\tvalid_1's binary_logloss: 0.14496\n",
      "[30]\ttraining's binary_logloss: 0.138382\tvalid_1's binary_logloss: 0.14463\n",
      "[31]\ttraining's binary_logloss: 0.137967\tvalid_1's binary_logloss: 0.144321\n",
      "[32]\ttraining's binary_logloss: 0.137538\tvalid_1's binary_logloss: 0.144015\n",
      "[33]\ttraining's binary_logloss: 0.137133\tvalid_1's binary_logloss: 0.143736\n",
      "[34]\ttraining's binary_logloss: 0.136746\tvalid_1's binary_logloss: 0.143467\n",
      "[35]\ttraining's binary_logloss: 0.136378\tvalid_1's binary_logloss: 0.143195\n",
      "[36]\ttraining's binary_logloss: 0.136018\tvalid_1's binary_logloss: 0.142954\n",
      "[37]\ttraining's binary_logloss: 0.135665\tvalid_1's binary_logloss: 0.142689\n",
      "[38]\ttraining's binary_logloss: 0.135301\tvalid_1's binary_logloss: 0.142444\n",
      "[39]\ttraining's binary_logloss: 0.134963\tvalid_1's binary_logloss: 0.142201\n",
      "[40]\ttraining's binary_logloss: 0.134626\tvalid_1's binary_logloss: 0.141976\n",
      "[41]\ttraining's binary_logloss: 0.134306\tvalid_1's binary_logloss: 0.141752\n",
      "[42]\ttraining's binary_logloss: 0.133979\tvalid_1's binary_logloss: 0.141527\n",
      "[43]\ttraining's binary_logloss: 0.133657\tvalid_1's binary_logloss: 0.141319\n",
      "[44]\ttraining's binary_logloss: 0.133367\tvalid_1's binary_logloss: 0.141114\n",
      "[45]\ttraining's binary_logloss: 0.133062\tvalid_1's binary_logloss: 0.140939\n",
      "[46]\ttraining's binary_logloss: 0.132773\tvalid_1's binary_logloss: 0.140768\n",
      "[47]\ttraining's binary_logloss: 0.132492\tvalid_1's binary_logloss: 0.140602\n",
      "[48]\ttraining's binary_logloss: 0.132215\tvalid_1's binary_logloss: 0.14042\n",
      "[49]\ttraining's binary_logloss: 0.131954\tvalid_1's binary_logloss: 0.140256\n",
      "[50]\ttraining's binary_logloss: 0.131697\tvalid_1's binary_logloss: 0.140093\n",
      "[51]\ttraining's binary_logloss: 0.131441\tvalid_1's binary_logloss: 0.139921\n",
      "[52]\ttraining's binary_logloss: 0.131198\tvalid_1's binary_logloss: 0.139766\n",
      "[53]\ttraining's binary_logloss: 0.130938\tvalid_1's binary_logloss: 0.139603\n",
      "[54]\ttraining's binary_logloss: 0.130684\tvalid_1's binary_logloss: 0.139433\n",
      "[55]\ttraining's binary_logloss: 0.130445\tvalid_1's binary_logloss: 0.139283\n",
      "[56]\ttraining's binary_logloss: 0.130207\tvalid_1's binary_logloss: 0.139136\n",
      "[57]\ttraining's binary_logloss: 0.129971\tvalid_1's binary_logloss: 0.138998\n",
      "[58]\ttraining's binary_logloss: 0.129745\tvalid_1's binary_logloss: 0.138881\n",
      "[59]\ttraining's binary_logloss: 0.129533\tvalid_1's binary_logloss: 0.138742\n",
      "[60]\ttraining's binary_logloss: 0.129321\tvalid_1's binary_logloss: 0.138615\n",
      "[61]\ttraining's binary_logloss: 0.129105\tvalid_1's binary_logloss: 0.138498\n",
      "[62]\ttraining's binary_logloss: 0.128893\tvalid_1's binary_logloss: 0.138383\n",
      "[63]\ttraining's binary_logloss: 0.128691\tvalid_1's binary_logloss: 0.13829\n",
      "[64]\ttraining's binary_logloss: 0.128483\tvalid_1's binary_logloss: 0.138189\n",
      "[65]\ttraining's binary_logloss: 0.128264\tvalid_1's binary_logloss: 0.138075\n",
      "[66]\ttraining's binary_logloss: 0.128065\tvalid_1's binary_logloss: 0.137989\n",
      "[67]\ttraining's binary_logloss: 0.127866\tvalid_1's binary_logloss: 0.137905\n",
      "[68]\ttraining's binary_logloss: 0.127674\tvalid_1's binary_logloss: 0.137832\n",
      "[69]\ttraining's binary_logloss: 0.127497\tvalid_1's binary_logloss: 0.137737\n",
      "[70]\ttraining's binary_logloss: 0.127305\tvalid_1's binary_logloss: 0.137659\n",
      "[71]\ttraining's binary_logloss: 0.127117\tvalid_1's binary_logloss: 0.137574\n",
      "[72]\ttraining's binary_logloss: 0.126936\tvalid_1's binary_logloss: 0.137501\n",
      "[73]\ttraining's binary_logloss: 0.126762\tvalid_1's binary_logloss: 0.137439\n",
      "[74]\ttraining's binary_logloss: 0.12659\tvalid_1's binary_logloss: 0.13737\n",
      "[75]\ttraining's binary_logloss: 0.126416\tvalid_1's binary_logloss: 0.137297\n",
      "[76]\ttraining's binary_logloss: 0.12625\tvalid_1's binary_logloss: 0.137249\n",
      "[77]\ttraining's binary_logloss: 0.126093\tvalid_1's binary_logloss: 0.137185\n",
      "[78]\ttraining's binary_logloss: 0.125941\tvalid_1's binary_logloss: 0.137126\n",
      "[79]\ttraining's binary_logloss: 0.12578\tvalid_1's binary_logloss: 0.137063\n",
      "[80]\ttraining's binary_logloss: 0.125606\tvalid_1's binary_logloss: 0.137017\n",
      "[81]\ttraining's binary_logloss: 0.125445\tvalid_1's binary_logloss: 0.136959\n",
      "[82]\ttraining's binary_logloss: 0.12526\tvalid_1's binary_logloss: 0.136902\n",
      "[83]\ttraining's binary_logloss: 0.1251\tvalid_1's binary_logloss: 0.136847\n",
      "[84]\ttraining's binary_logloss: 0.12495\tvalid_1's binary_logloss: 0.136787\n",
      "[85]\ttraining's binary_logloss: 0.124762\tvalid_1's binary_logloss: 0.136712\n",
      "[86]\ttraining's binary_logloss: 0.12462\tvalid_1's binary_logloss: 0.136661\n",
      "[87]\ttraining's binary_logloss: 0.124484\tvalid_1's binary_logloss: 0.136603\n",
      "[88]\ttraining's binary_logloss: 0.124324\tvalid_1's binary_logloss: 0.136552\n",
      "[89]\ttraining's binary_logloss: 0.124177\tvalid_1's binary_logloss: 0.136504\n",
      "[90]\ttraining's binary_logloss: 0.124047\tvalid_1's binary_logloss: 0.136457\n",
      "[91]\ttraining's binary_logloss: 0.123914\tvalid_1's binary_logloss: 0.136417\n",
      "[92]\ttraining's binary_logloss: 0.123775\tvalid_1's binary_logloss: 0.136376\n",
      "[93]\ttraining's binary_logloss: 0.123627\tvalid_1's binary_logloss: 0.136319\n",
      "[94]\ttraining's binary_logloss: 0.123493\tvalid_1's binary_logloss: 0.136278\n",
      "[95]\ttraining's binary_logloss: 0.123351\tvalid_1's binary_logloss: 0.13624\n",
      "[96]\ttraining's binary_logloss: 0.123211\tvalid_1's binary_logloss: 0.136193\n",
      "[97]\ttraining's binary_logloss: 0.123081\tvalid_1's binary_logloss: 0.136156\n",
      "[98]\ttraining's binary_logloss: 0.122953\tvalid_1's binary_logloss: 0.136131\n",
      "[99]\ttraining's binary_logloss: 0.122835\tvalid_1's binary_logloss: 0.136099\n",
      "[100]\ttraining's binary_logloss: 0.122702\tvalid_1's binary_logloss: 0.13606\n",
      "[101]\ttraining's binary_logloss: 0.122572\tvalid_1's binary_logloss: 0.136024\n",
      "[102]\ttraining's binary_logloss: 0.122437\tvalid_1's binary_logloss: 0.135999\n",
      "[103]\ttraining's binary_logloss: 0.122305\tvalid_1's binary_logloss: 0.135976\n",
      "[104]\ttraining's binary_logloss: 0.12218\tvalid_1's binary_logloss: 0.135946\n",
      "[105]\ttraining's binary_logloss: 0.122066\tvalid_1's binary_logloss: 0.135911\n",
      "[106]\ttraining's binary_logloss: 0.121944\tvalid_1's binary_logloss: 0.135886\n",
      "[107]\ttraining's binary_logloss: 0.121825\tvalid_1's binary_logloss: 0.13586\n",
      "[108]\ttraining's binary_logloss: 0.121701\tvalid_1's binary_logloss: 0.13584\n",
      "[109]\ttraining's binary_logloss: 0.121582\tvalid_1's binary_logloss: 0.135816\n",
      "[110]\ttraining's binary_logloss: 0.121477\tvalid_1's binary_logloss: 0.135787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8402565446046388"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators= int(best_params_lgbm['n_estimators'])\n",
    "                            , learning_rate = best_params_lgbm['learning_rate'])\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr\n",
    "                 , early_stopping_rounds=80\n",
    "                 , eval_metric = 'logloss'\n",
    "                 , eval_set = evals\n",
    "                 , verbose = True\n",
    "                 )\n",
    "pred_proba_lgbm = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, pred_proba_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBM vs LGBM 평가\n",
    "1. AUC 기준 평가 결과\n",
    "2. 각각의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "auc : 0.840595060504169\n",
      "n_estimators : 230\n",
      "learning_rate : 0.12212214378271394\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#XGBM\n",
    "print(f'''\n",
    "auc : {roc_auc_score(y_test, pred_proba)}\n",
    "n_estimators : {best_model.get_params()['n_estimators']}\n",
    "learning_rate : {best_model.get_params()['learning_rate']}\n",
    "      ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "auc : 0.8402565446046388\n",
      "n_estimators : 110.0\n",
      "learning_rate : 0.019374568079732202\n",
      "\n",
      "xgbm이 더큰가? True\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#LGBM\n",
    "print(f'''\n",
    "auc : {roc_auc_score(y_test, pred_proba_lgbm)}\n",
    "n_estimators : {best_params_lgbm['n_estimators']}\n",
    "learning_rate : {best_params_lgbm['learning_rate']}\n",
    "\n",
    "xgbm이 더큰가? {roc_auc_score(y_test, pred_proba) > roc_auc_score(y_test, pred_proba_lgbm)}\n",
    "      ''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LGBM  \n",
    "auc : 0.840595060504169  \n",
    "n_estimators : 500  \n",
    "learning_rate : 0.01  \n",
    "early_stopping_rounds : 80  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼오피티, LGBM 추가 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화 파라미터 기준 모델 평가\n",
    "\n",
    "n_estimator=500\n",
    "learning_rate = 0.15\n",
    "max_depth = 5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
